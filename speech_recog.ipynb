{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "premium-tobago",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import python_speech_features\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seventh-audio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['on', 'two', 'one', 'three', 'off']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './dataset'\n",
    "targets = [name for name in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, name))]\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reasonable-adjustment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3845\n",
      "3880\n",
      "3890\n",
      "3727\n",
      "3745\n",
      "Total samples: 19087\n"
     ]
    }
   ],
   "source": [
    "num_samples = 0\n",
    "for target in targets:\n",
    "    print(len(os.listdir(os.path.join(dataset_path, target))))\n",
    "    num_samples += len(os.listdir(os.path.join(dataset_path, target)))\n",
    "print('Total samples:', num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atlantic-perception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/on\n",
      "./dataset/two\n",
      "./dataset/one\n",
      "./dataset/three\n",
      "./dataset/off\n",
      "19087\n",
      "19087\n"
     ]
    }
   ],
   "source": [
    "audio_files = []\n",
    "y = []\n",
    "for index, target in enumerate(targets):\n",
    "    print(os.path.join(dataset_path, target))\n",
    "    audio_files.append(os.listdir(os.path.join(dataset_path, target)))\n",
    "    y.append(np.ones(len(audio_files[index])) * index)\n",
    "audio_files = [item for sublist in audio_files for item in sublist]\n",
    "y = [item for sublist in y for item in sublist]\n",
    "print(len(audio_files))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accurate-assignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15269\n",
      "1909\n",
      "1909\n",
      "15269\n",
      "1909\n",
      "1909\n"
     ]
    }
   ],
   "source": [
    "audio_files_train, audio_files_val_test, y_orig_train, y_orig_val_train = train_test_split(audio_files, y, test_size = 0.2)\n",
    "audio_files_val, audio_files_test, y_orig_val, y_orig_test = train_test_split(audio_files_val_test, y_orig_val_train, test_size = 0.5)\n",
    "print(len(audio_files_train))\n",
    "print(len(audio_files_val))\n",
    "print(len(audio_files_test))\n",
    "print(len(y_orig_train))\n",
    "print(len(y_orig_val))\n",
    "val_set_size = len(y_orig_val)\n",
    "print(len(y_orig_test))\n",
    "test_set_size = len(y_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "north-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mfcc(path):\n",
    "    signal, fs = librosa.load(path, sr=16000)\n",
    "    mfccs = python_speech_features.base.mfcc(signal, \n",
    "                                             samplerate=fs,\n",
    "                                             winlen = 0.025,\n",
    "                                             winstep = 0.01,\n",
    "                                             numcep = 20,\n",
    "                                             nfilt = 20,\n",
    "                                             nfft = 2048,\n",
    "                                             preemph = 0,\n",
    "                                             ceplifter = 0,\n",
    "                                             appendEnergy = False,\n",
    "                                             winfunc = np.hanning)\n",
    "    return mfccs.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metric-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(in_audio, in_y):\n",
    "    prob_cnt = 0\n",
    "    out_x = []\n",
    "    out_y = []\n",
    "        \n",
    "    for index, audio in enumerate(in_audio):\n",
    "    \n",
    "        path = os.path.join(dataset_path, targets[int(in_y[index])], audio)\n",
    "        \n",
    "        if not path.endswith('.wav'):\n",
    "            continue\n",
    "\n",
    "        mfccs = calc_mfcc(path)\n",
    "\n",
    "        if mfccs.shape[1] == 99:\n",
    "            out_x.append(mfccs)\n",
    "            out_y.append(in_y[index])\n",
    "        else:\n",
    "            print('Dropped:', index, mfccs.shape)\n",
    "            prob_cnt += 1\n",
    "            \n",
    "    return out_x, out_y, prob_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "smaller-cisco",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 42 (20, 92)\n",
      "Dropped: 54 (20, 93)\n",
      "Dropped: 103 (20, 50)\n",
      "Dropped: 112 (20, 83)\n",
      "Dropped: 126 (20, 83)\n",
      "Dropped: 128 (20, 93)\n",
      "Dropped: 129 (20, 97)\n",
      "Dropped: 131 (20, 72)\n",
      "Dropped: 138 (20, 67)\n",
      "Dropped: 143 (20, 78)\n",
      "Dropped: 168 (20, 81)\n",
      "Dropped: 171 (20, 97)\n",
      "Dropped: 176 (20, 74)\n",
      "Dropped: 191 (20, 55)\n",
      "Dropped: 198 (20, 74)\n",
      "Dropped: 231 (20, 67)\n",
      "Dropped: 240 (20, 84)\n",
      "Dropped: 243 (20, 72)\n",
      "Dropped: 259 (20, 97)\n",
      "Dropped: 260 (20, 38)\n",
      "Dropped: 265 (20, 84)\n",
      "Dropped: 302 (20, 78)\n",
      "Dropped: 313 (20, 89)\n",
      "Dropped: 322 (20, 89)\n",
      "Dropped: 324 (20, 97)\n",
      "Dropped: 327 (20, 87)\n",
      "Dropped: 343 (20, 80)\n",
      "Dropped: 348 (20, 74)\n",
      "Dropped: 360 (20, 83)\n",
      "Dropped: 369 (20, 83)\n",
      "Dropped: 370 (20, 87)\n",
      "Dropped: 396 (20, 84)\n",
      "Dropped: 407 (20, 84)\n",
      "Dropped: 409 (20, 93)\n",
      "Dropped: 420 (20, 87)\n",
      "Dropped: 429 (20, 97)\n",
      "Dropped: 443 (20, 93)\n",
      "Dropped: 450 (20, 84)\n",
      "Dropped: 460 (20, 89)\n",
      "Dropped: 479 (20, 75)\n",
      "Dropped: 483 (20, 97)\n",
      "Dropped: 484 (20, 78)\n",
      "Dropped: 490 (20, 78)\n",
      "Dropped: 491 (20, 97)\n",
      "Dropped: 493 (20, 93)\n",
      "Dropped: 494 (20, 76)\n",
      "Dropped: 495 (20, 89)\n",
      "Dropped: 499 (20, 89)\n",
      "Dropped: 502 (20, 97)\n",
      "Dropped: 505 (20, 69)\n",
      "Dropped: 526 (20, 83)\n",
      "Dropped: 528 (20, 97)\n",
      "Dropped: 532 (20, 87)\n",
      "Dropped: 535 (20, 76)\n",
      "Dropped: 537 (20, 54)\n",
      "Dropped: 540 (20, 74)\n",
      "Dropped: 546 (20, 72)\n",
      "Dropped: 550 (20, 63)\n",
      "Dropped: 574 (20, 78)\n",
      "Dropped: 589 (20, 67)\n",
      "Dropped: 600 (20, 87)\n",
      "Dropped: 605 (20, 89)\n",
      "Dropped: 633 (20, 84)\n",
      "Dropped: 637 (20, 97)\n",
      "Dropped: 643 (20, 54)\n",
      "Dropped: 656 (20, 87)\n",
      "Dropped: 672 (20, 93)\n",
      "Dropped: 697 (20, 87)\n",
      "Dropped: 705 (20, 89)\n",
      "Dropped: 713 (20, 97)\n",
      "Dropped: 734 (20, 74)\n",
      "Dropped: 744 (20, 80)\n",
      "Dropped: 751 (20, 83)\n",
      "Dropped: 757 (20, 92)\n",
      "Dropped: 766 (20, 54)\n",
      "Dropped: 769 (20, 74)\n",
      "Dropped: 772 (20, 74)\n",
      "Dropped: 795 (20, 93)\n",
      "Dropped: 820 (20, 93)\n",
      "Dropped: 823 (20, 74)\n",
      "Dropped: 825 (20, 84)\n",
      "Dropped: 827 (20, 75)\n",
      "Dropped: 833 (20, 50)\n",
      "Dropped: 840 (20, 97)\n",
      "Dropped: 867 (20, 55)\n",
      "Dropped: 871 (20, 92)\n",
      "Dropped: 878 (20, 97)\n",
      "Dropped: 881 (20, 76)\n",
      "Dropped: 900 (20, 97)\n",
      "Dropped: 910 (20, 98)\n",
      "Dropped: 912 (20, 74)\n",
      "Dropped: 923 (20, 59)\n",
      "Dropped: 928 (20, 83)\n",
      "Dropped: 932 (20, 89)\n",
      "Dropped: 934 (20, 89)\n",
      "Dropped: 952 (20, 78)\n",
      "Dropped: 1016 (20, 83)\n",
      "Dropped: 1027 (20, 97)\n",
      "Dropped: 1035 (20, 76)\n",
      "Dropped: 1044 (20, 93)\n",
      "Dropped: 1049 (20, 76)\n",
      "Dropped: 1060 (20, 75)\n",
      "Dropped: 1067 (20, 63)\n",
      "Dropped: 1068 (20, 80)\n",
      "Dropped: 1072 (20, 93)\n",
      "Dropped: 1109 (20, 74)\n",
      "Dropped: 1115 (20, 50)\n",
      "Dropped: 1117 (20, 74)\n",
      "Dropped: 1119 (20, 72)\n",
      "Dropped: 1120 (20, 78)\n",
      "Dropped: 1124 (20, 64)\n",
      "Dropped: 1126 (20, 92)\n",
      "Dropped: 1130 (20, 84)\n",
      "Dropped: 1150 (20, 97)\n",
      "Dropped: 1151 (20, 76)\n",
      "Dropped: 1177 (20, 75)\n",
      "Dropped: 1221 (20, 74)\n",
      "Dropped: 1235 (20, 97)\n",
      "Dropped: 1246 (20, 89)\n",
      "Dropped: 1260 (20, 97)\n",
      "Dropped: 1296 (20, 87)\n",
      "Dropped: 1298 (20, 55)\n",
      "Dropped: 1300 (20, 50)\n",
      "Dropped: 1309 (20, 93)\n",
      "Dropped: 1318 (20, 76)\n",
      "Dropped: 1325 (20, 83)\n",
      "Dropped: 1337 (20, 97)\n",
      "Dropped: 1346 (20, 89)\n",
      "Dropped: 1372 (20, 75)\n",
      "Dropped: 1383 (20, 84)\n",
      "Dropped: 1401 (20, 67)\n",
      "Dropped: 1406 (20, 73)\n",
      "Dropped: 1414 (20, 97)\n",
      "Dropped: 1422 (20, 74)\n",
      "Dropped: 1436 (20, 89)\n",
      "Dropped: 1440 (20, 83)\n",
      "Dropped: 1446 (20, 92)\n",
      "Dropped: 1447 (20, 50)\n",
      "Dropped: 1459 (20, 97)\n",
      "Dropped: 1461 (20, 89)\n",
      "Dropped: 1488 (20, 74)\n",
      "Dropped: 1498 (20, 73)\n",
      "Dropped: 1508 (20, 92)\n",
      "Dropped: 1556 (20, 67)\n",
      "Dropped: 1562 (20, 64)\n",
      "Dropped: 1566 (20, 97)\n",
      "Dropped: 1585 (20, 97)\n",
      "Dropped: 1588 (20, 80)\n",
      "Dropped: 1614 (20, 83)\n",
      "Dropped: 1615 (20, 87)\n",
      "Dropped: 1629 (20, 89)\n",
      "Dropped: 1636 (20, 80)\n",
      "Dropped: 1648 (20, 72)\n",
      "Dropped: 1650 (20, 97)\n",
      "Dropped: 1654 (20, 92)\n",
      "Dropped: 1665 (20, 78)\n",
      "Dropped: 1679 (20, 80)\n",
      "Dropped: 1683 (20, 76)\n",
      "Dropped: 1688 (20, 80)\n",
      "Dropped: 1697 (20, 84)\n",
      "Dropped: 1701 (20, 97)\n",
      "Dropped: 1708 (20, 95)\n",
      "Dropped: 1735 (20, 97)\n",
      "Dropped: 1750 (20, 93)\n",
      "Dropped: 1763 (20, 72)\n",
      "Dropped: 1779 (20, 87)\n",
      "Dropped: 1780 (20, 82)\n",
      "Dropped: 1783 (20, 59)\n",
      "Dropped: 1787 (20, 59)\n",
      "Dropped: 1797 (20, 87)\n",
      "Dropped: 1810 (20, 89)\n",
      "Dropped: 1814 (20, 84)\n",
      "Dropped: 1849 (20, 72)\n",
      "Dropped: 1850 (20, 64)\n",
      "Dropped: 1852 (20, 80)\n",
      "Dropped: 1853 (20, 74)\n",
      "Dropped: 1857 (20, 83)\n",
      "Dropped: 1884 (20, 72)\n",
      "Dropped: 1887 (20, 78)\n",
      "Dropped: 1920 (20, 75)\n",
      "Dropped: 1941 (20, 97)\n",
      "Dropped: 1953 (20, 80)\n",
      "Dropped: 1954 (20, 97)\n",
      "Dropped: 1960 (20, 80)\n",
      "Dropped: 1995 (20, 63)\n",
      "Dropped: 2004 (20, 67)\n",
      "Dropped: 2005 (20, 74)\n",
      "Dropped: 2013 (20, 84)\n",
      "Dropped: 2014 (20, 84)\n",
      "Dropped: 2016 (20, 74)\n",
      "Dropped: 2017 (20, 80)\n",
      "Dropped: 2027 (20, 97)\n",
      "Dropped: 2036 (20, 97)\n",
      "Dropped: 2042 (20, 72)\n",
      "Dropped: 2055 (20, 80)\n",
      "Dropped: 2059 (20, 84)\n",
      "Dropped: 2062 (20, 74)\n",
      "Dropped: 2065 (20, 84)\n",
      "Dropped: 2066 (20, 87)\n",
      "Dropped: 2069 (20, 63)\n",
      "Dropped: 2073 (20, 73)\n",
      "Dropped: 2094 (20, 84)\n",
      "Dropped: 2097 (20, 67)\n",
      "Dropped: 2100 (20, 78)\n",
      "Dropped: 2130 (20, 78)\n",
      "Dropped: 2144 (20, 97)\n",
      "Dropped: 2162 (20, 73)\n",
      "Dropped: 2166 (20, 87)\n",
      "Dropped: 2171 (20, 78)\n",
      "Dropped: 2185 (20, 93)\n",
      "Dropped: 2200 (20, 97)\n",
      "Dropped: 2216 (20, 93)\n",
      "Dropped: 2253 (20, 76)\n",
      "Dropped: 2263 (20, 97)\n",
      "Dropped: 2270 (20, 59)\n",
      "Dropped: 2273 (20, 93)\n",
      "Dropped: 2303 (20, 83)\n",
      "Dropped: 2323 (20, 74)\n",
      "Dropped: 2327 (20, 75)\n",
      "Dropped: 2334 (20, 84)\n",
      "Dropped: 2345 (20, 87)\n",
      "Dropped: 2359 (20, 84)\n",
      "Dropped: 2379 (20, 76)\n",
      "Dropped: 2383 (20, 93)\n",
      "Dropped: 2387 (20, 63)\n",
      "Dropped: 2438 (20, 84)\n",
      "Dropped: 2470 (20, 83)\n",
      "Dropped: 2473 (20, 87)\n",
      "Dropped: 2480 (20, 59)\n",
      "Dropped: 2488 (20, 72)\n",
      "Dropped: 2495 (20, 84)\n",
      "Dropped: 2496 (20, 54)\n",
      "Dropped: 2504 (20, 89)\n",
      "Dropped: 2533 (20, 83)\n",
      "Dropped: 2544 (20, 89)\n",
      "Dropped: 2556 (20, 84)\n",
      "Dropped: 2562 (20, 97)\n",
      "Dropped: 2581 (20, 32)\n",
      "Dropped: 2592 (20, 74)\n",
      "Dropped: 2607 (20, 74)\n",
      "Dropped: 2623 (20, 75)\n",
      "Dropped: 2631 (20, 93)\n",
      "Dropped: 2639 (20, 97)\n",
      "Dropped: 2643 (20, 74)\n",
      "Dropped: 2683 (20, 97)\n",
      "Dropped: 2689 (20, 83)\n",
      "Dropped: 2690 (20, 83)\n",
      "Dropped: 2693 (20, 73)\n",
      "Dropped: 2715 (20, 92)\n",
      "Dropped: 2736 (20, 74)\n",
      "Dropped: 2737 (20, 93)\n",
      "Dropped: 2746 (20, 83)\n",
      "Dropped: 2750 (20, 37)\n",
      "Dropped: 2757 (20, 84)\n",
      "Dropped: 2776 (20, 97)\n",
      "Dropped: 2783 (20, 78)\n",
      "Dropped: 2794 (20, 97)\n",
      "Dropped: 2812 (20, 80)\n",
      "Dropped: 2821 (20, 54)\n",
      "Dropped: 2837 (20, 89)\n",
      "Dropped: 2838 (20, 92)\n",
      "Dropped: 2872 (20, 89)\n",
      "Dropped: 2873 (20, 97)\n",
      "Dropped: 2886 (20, 72)\n",
      "Dropped: 2894 (20, 69)\n",
      "Dropped: 2905 (20, 92)\n",
      "Dropped: 2906 (20, 97)\n",
      "Dropped: 2910 (20, 97)\n",
      "Dropped: 2920 (20, 97)\n",
      "Dropped: 2921 (20, 92)\n",
      "Dropped: 2956 (20, 72)\n",
      "Dropped: 2961 (20, 73)\n",
      "Dropped: 2962 (20, 96)\n",
      "Dropped: 2972 (20, 59)\n",
      "Dropped: 2974 (20, 76)\n",
      "Dropped: 2981 (20, 74)\n",
      "Dropped: 2989 (20, 78)\n",
      "Dropped: 2993 (20, 80)\n",
      "Dropped: 3002 (20, 75)\n",
      "Dropped: 3009 (20, 89)\n",
      "Dropped: 3029 (20, 83)\n",
      "Dropped: 3032 (20, 59)\n",
      "Dropped: 3043 (20, 80)\n",
      "Dropped: 3066 (20, 78)\n",
      "Dropped: 3082 (20, 97)\n",
      "Dropped: 3091 (20, 87)\n",
      "Dropped: 3114 (20, 84)\n",
      "Dropped: 3120 (20, 63)\n",
      "Dropped: 3149 (20, 54)\n",
      "Dropped: 3151 (20, 73)\n",
      "Dropped: 3152 (20, 97)\n",
      "Dropped: 3171 (20, 73)\n",
      "Dropped: 3173 (20, 97)\n",
      "Dropped: 3195 (20, 59)\n",
      "Dropped: 3205 (20, 73)\n",
      "Dropped: 3207 (20, 72)\n",
      "Dropped: 3215 (20, 92)\n",
      "Dropped: 3220 (20, 97)\n",
      "Dropped: 3222 (20, 69)\n",
      "Dropped: 3224 (20, 63)\n",
      "Dropped: 3233 (20, 63)\n",
      "Dropped: 3246 (20, 84)\n",
      "Dropped: 3247 (20, 89)\n",
      "Dropped: 3258 (20, 80)\n",
      "Dropped: 3272 (20, 97)\n",
      "Dropped: 3285 (20, 80)\n",
      "Dropped: 3300 (20, 93)\n",
      "Dropped: 3312 (20, 78)\n",
      "Dropped: 3320 (20, 72)\n",
      "Dropped: 3335 (20, 84)\n",
      "Dropped: 3356 (20, 44)\n",
      "Dropped: 3371 (20, 89)\n",
      "Dropped: 3376 (20, 78)\n",
      "Dropped: 3379 (20, 97)\n",
      "Dropped: 3388 (20, 93)\n",
      "Dropped: 3394 (20, 97)\n",
      "Dropped: 3412 (20, 93)\n",
      "Dropped: 3416 (20, 69)\n",
      "Dropped: 3451 (20, 97)\n",
      "Dropped: 3468 (20, 63)\n",
      "Dropped: 3473 (20, 93)\n",
      "Dropped: 3477 (20, 93)\n",
      "Dropped: 3493 (20, 83)\n",
      "Dropped: 3503 (20, 97)\n",
      "Dropped: 3546 (20, 80)\n",
      "Dropped: 3554 (20, 69)\n",
      "Dropped: 3555 (20, 78)\n",
      "Dropped: 3562 (20, 97)\n",
      "Dropped: 3595 (20, 67)\n",
      "Dropped: 3623 (20, 97)\n",
      "Dropped: 3624 (20, 91)\n",
      "Dropped: 3625 (20, 80)\n",
      "Dropped: 3636 (20, 89)\n",
      "Dropped: 3650 (20, 76)\n",
      "Dropped: 3659 (20, 54)\n",
      "Dropped: 3663 (20, 73)\n",
      "Dropped: 3664 (20, 92)\n",
      "Dropped: 3677 (20, 93)\n",
      "Dropped: 3684 (20, 97)\n",
      "Dropped: 3685 (20, 87)\n",
      "Dropped: 3697 (20, 97)\n",
      "Dropped: 3699 (20, 75)\n",
      "Dropped: 3707 (20, 97)\n",
      "Dropped: 3716 (20, 97)\n",
      "Dropped: 3725 (20, 59)\n",
      "Dropped: 3733 (20, 80)\n",
      "Dropped: 3735 (20, 97)\n",
      "Dropped: 3745 (20, 74)\n",
      "Dropped: 3747 (20, 92)\n",
      "Dropped: 3767 (20, 97)\n",
      "Dropped: 3769 (20, 63)\n",
      "Dropped: 3770 (20, 92)\n",
      "Dropped: 3773 (20, 59)\n",
      "Dropped: 3776 (20, 78)\n",
      "Dropped: 3785 (20, 89)\n",
      "Dropped: 3801 (20, 93)\n",
      "Dropped: 3816 (20, 84)\n",
      "Dropped: 3819 (20, 87)\n",
      "Dropped: 3858 (20, 78)\n",
      "Dropped: 3871 (20, 67)\n",
      "Dropped: 3890 (20, 92)\n",
      "Dropped: 3896 (20, 93)\n",
      "Dropped: 3898 (20, 73)\n",
      "Dropped: 3903 (20, 84)\n",
      "Dropped: 3908 (20, 92)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 3910 (20, 93)\n",
      "Dropped: 3911 (20, 89)\n",
      "Dropped: 3917 (20, 78)\n",
      "Dropped: 3918 (20, 97)\n",
      "Dropped: 3927 (20, 69)\n",
      "Dropped: 3940 (20, 76)\n",
      "Dropped: 3944 (20, 59)\n",
      "Dropped: 3977 (20, 87)\n",
      "Dropped: 3981 (20, 89)\n",
      "Dropped: 3988 (20, 72)\n",
      "Dropped: 4012 (20, 90)\n",
      "Dropped: 4024 (20, 92)\n",
      "Dropped: 4041 (20, 76)\n",
      "Dropped: 4048 (20, 63)\n",
      "Dropped: 4054 (20, 72)\n",
      "Dropped: 4060 (20, 74)\n",
      "Dropped: 4063 (20, 69)\n",
      "Dropped: 4077 (20, 67)\n",
      "Dropped: 4097 (20, 97)\n",
      "Dropped: 4110 (20, 87)\n",
      "Dropped: 4111 (20, 59)\n",
      "Dropped: 4117 (20, 93)\n",
      "Dropped: 4165 (20, 89)\n",
      "Dropped: 4181 (20, 84)\n",
      "Dropped: 4189 (20, 93)\n",
      "Dropped: 4193 (20, 78)\n",
      "Dropped: 4232 (20, 97)\n",
      "Dropped: 4245 (20, 93)\n",
      "Dropped: 4249 (20, 80)\n",
      "Dropped: 4253 (20, 89)\n",
      "Dropped: 4256 (20, 42)\n",
      "Dropped: 4265 (20, 82)\n",
      "Dropped: 4270 (20, 89)\n",
      "Dropped: 4272 (20, 73)\n",
      "Dropped: 4294 (20, 80)\n",
      "Dropped: 4322 (20, 89)\n",
      "Dropped: 4328 (20, 72)\n",
      "Dropped: 4332 (20, 97)\n",
      "Dropped: 4335 (20, 84)\n",
      "Dropped: 4340 (20, 84)\n",
      "Dropped: 4344 (20, 93)\n",
      "Dropped: 4370 (20, 72)\n",
      "Dropped: 4403 (20, 84)\n",
      "Dropped: 4432 (20, 64)\n",
      "Dropped: 4448 (20, 83)\n",
      "Dropped: 4457 (20, 97)\n",
      "Dropped: 4462 (20, 63)\n",
      "Dropped: 4464 (20, 75)\n",
      "Dropped: 4466 (20, 78)\n",
      "Dropped: 4492 (20, 83)\n",
      "Dropped: 4510 (20, 63)\n",
      "Dropped: 4512 (20, 67)\n",
      "Dropped: 4515 (20, 75)\n",
      "Dropped: 4516 (20, 74)\n",
      "Dropped: 4534 (20, 87)\n",
      "Dropped: 4559 (20, 84)\n",
      "Dropped: 4562 (20, 97)\n",
      "Dropped: 4574 (20, 67)\n",
      "Dropped: 4579 (20, 84)\n",
      "Dropped: 4583 (20, 92)\n",
      "Dropped: 4587 (20, 69)\n",
      "Dropped: 4594 (20, 92)\n",
      "Dropped: 4600 (20, 93)\n",
      "Dropped: 4623 (20, 67)\n",
      "Dropped: 4643 (20, 78)\n",
      "Dropped: 4656 (20, 57)\n",
      "Dropped: 4660 (20, 67)\n",
      "Dropped: 4661 (20, 78)\n",
      "Dropped: 4668 (20, 92)\n",
      "Dropped: 4686 (20, 46)\n",
      "Dropped: 4693 (20, 74)\n",
      "Dropped: 4724 (20, 92)\n",
      "Dropped: 4747 (20, 72)\n",
      "Dropped: 4776 (20, 37)\n",
      "Dropped: 4788 (20, 73)\n",
      "Dropped: 4791 (20, 78)\n",
      "Dropped: 4798 (20, 73)\n",
      "Dropped: 4830 (20, 93)\n",
      "Dropped: 4844 (20, 97)\n",
      "Dropped: 4850 (20, 74)\n",
      "Dropped: 4864 (20, 93)\n",
      "Dropped: 4868 (20, 89)\n",
      "Dropped: 4872 (20, 97)\n",
      "Dropped: 4879 (20, 59)\n",
      "Dropped: 4886 (20, 87)\n",
      "Dropped: 4896 (20, 59)\n",
      "Dropped: 4930 (20, 59)\n",
      "Dropped: 4939 (20, 84)\n",
      "Dropped: 4940 (20, 74)\n",
      "Dropped: 4947 (20, 55)\n",
      "Dropped: 4954 (20, 83)\n",
      "Dropped: 4971 (20, 50)\n",
      "Dropped: 4981 (20, 92)\n",
      "Dropped: 4982 (20, 80)\n",
      "Dropped: 4985 (20, 54)\n",
      "Dropped: 4992 (20, 74)\n",
      "Dropped: 4997 (20, 92)\n",
      "Dropped: 5005 (20, 84)\n",
      "Dropped: 5007 (20, 78)\n",
      "Dropped: 5025 (20, 97)\n",
      "Dropped: 5052 (20, 92)\n",
      "Dropped: 5058 (20, 50)\n",
      "Dropped: 5075 (20, 42)\n",
      "Dropped: 5082 (20, 73)\n",
      "Dropped: 5087 (20, 87)\n",
      "Dropped: 5095 (20, 93)\n",
      "Dropped: 5118 (20, 93)\n",
      "Dropped: 5135 (20, 87)\n",
      "Dropped: 5144 (20, 69)\n",
      "Dropped: 5146 (20, 74)\n",
      "Dropped: 5167 (20, 59)\n",
      "Dropped: 5170 (20, 97)\n",
      "Dropped: 5188 (20, 87)\n",
      "Dropped: 5196 (20, 92)\n",
      "Dropped: 5206 (20, 63)\n",
      "Dropped: 5219 (20, 74)\n",
      "Dropped: 5221 (20, 72)\n",
      "Dropped: 5227 (20, 92)\n",
      "Dropped: 5232 (20, 89)\n",
      "Dropped: 5234 (20, 83)\n",
      "Dropped: 5265 (20, 97)\n",
      "Dropped: 5268 (20, 63)\n",
      "Dropped: 5291 (20, 75)\n",
      "Dropped: 5294 (20, 50)\n",
      "Dropped: 5312 (20, 74)\n",
      "Dropped: 5318 (20, 84)\n",
      "Dropped: 5345 (20, 76)\n",
      "Dropped: 5358 (20, 69)\n",
      "Dropped: 5362 (20, 84)\n",
      "Dropped: 5365 (20, 89)\n",
      "Dropped: 5402 (20, 59)\n",
      "Dropped: 5417 (20, 80)\n",
      "Dropped: 5422 (20, 97)\n",
      "Dropped: 5456 (20, 63)\n",
      "Dropped: 5473 (20, 63)\n",
      "Dropped: 5494 (20, 83)\n",
      "Dropped: 5495 (20, 97)\n",
      "Dropped: 5501 (20, 89)\n",
      "Dropped: 5525 (20, 59)\n",
      "Dropped: 5540 (20, 75)\n",
      "Dropped: 5542 (20, 73)\n",
      "Dropped: 5553 (20, 76)\n",
      "Dropped: 5566 (20, 72)\n",
      "Dropped: 5569 (20, 97)\n",
      "Dropped: 5578 (20, 50)\n",
      "Dropped: 5586 (20, 67)\n",
      "Dropped: 5590 (20, 97)\n",
      "Dropped: 5599 (20, 92)\n",
      "Dropped: 5601 (20, 87)\n",
      "Dropped: 5610 (20, 93)\n",
      "Dropped: 5638 (20, 80)\n",
      "Dropped: 5640 (20, 41)\n",
      "Dropped: 5644 (20, 93)\n",
      "Dropped: 5649 (20, 72)\n",
      "Dropped: 5656 (20, 92)\n",
      "Dropped: 5674 (20, 92)\n",
      "Dropped: 5677 (20, 97)\n",
      "Dropped: 5678 (20, 59)\n",
      "Dropped: 5683 (20, 93)\n",
      "Dropped: 5688 (20, 64)\n",
      "Dropped: 5696 (20, 84)\n",
      "Dropped: 5699 (20, 69)\n",
      "Dropped: 5709 (20, 50)\n",
      "Dropped: 5711 (20, 73)\n",
      "Dropped: 5715 (20, 76)\n",
      "Dropped: 5722 (20, 83)\n",
      "Dropped: 5724 (20, 84)\n",
      "Dropped: 5738 (20, 93)\n",
      "Dropped: 5743 (20, 87)\n",
      "Dropped: 5752 (20, 89)\n",
      "Dropped: 5753 (20, 97)\n",
      "Dropped: 5766 (20, 78)\n",
      "Dropped: 5767 (20, 54)\n",
      "Dropped: 5781 (20, 59)\n",
      "Dropped: 5783 (20, 83)\n",
      "Dropped: 5812 (20, 97)\n",
      "Dropped: 5813 (20, 93)\n",
      "Dropped: 5814 (20, 92)\n",
      "Dropped: 5816 (20, 97)\n",
      "Dropped: 5841 (20, 78)\n",
      "Dropped: 5854 (20, 67)\n",
      "Dropped: 5865 (20, 97)\n",
      "Dropped: 5868 (20, 87)\n",
      "Dropped: 5872 (20, 87)\n",
      "Dropped: 5873 (20, 59)\n",
      "Dropped: 5895 (20, 76)\n",
      "Dropped: 5899 (20, 87)\n",
      "Dropped: 5923 (20, 80)\n",
      "Dropped: 5945 (20, 74)\n",
      "Dropped: 5950 (20, 78)\n",
      "Dropped: 5951 (20, 89)\n",
      "Dropped: 5963 (20, 87)\n",
      "Dropped: 5978 (20, 73)\n",
      "Dropped: 5988 (20, 69)\n",
      "Dropped: 5990 (20, 78)\n",
      "Dropped: 5999 (20, 78)\n",
      "Dropped: 6019 (20, 74)\n",
      "Dropped: 6023 (20, 76)\n",
      "Dropped: 6026 (20, 64)\n",
      "Dropped: 6038 (20, 74)\n",
      "Dropped: 6039 (20, 67)\n",
      "Dropped: 6042 (20, 45)\n",
      "Dropped: 6058 (20, 93)\n",
      "Dropped: 6070 (20, 73)\n",
      "Dropped: 6082 (20, 93)\n",
      "Dropped: 6097 (20, 64)\n",
      "Dropped: 6103 (20, 84)\n",
      "Dropped: 6107 (20, 64)\n",
      "Dropped: 6111 (20, 89)\n",
      "Dropped: 6125 (20, 86)\n",
      "Dropped: 6128 (20, 72)\n",
      "Dropped: 6140 (20, 80)\n",
      "Dropped: 6173 (20, 97)\n",
      "Dropped: 6174 (20, 78)\n",
      "Dropped: 6177 (20, 74)\n",
      "Dropped: 6189 (20, 97)\n",
      "Dropped: 6190 (20, 75)\n",
      "Dropped: 6207 (20, 59)\n",
      "Dropped: 6214 (20, 80)\n",
      "Dropped: 6227 (20, 72)\n",
      "Dropped: 6258 (20, 67)\n",
      "Dropped: 6301 (20, 74)\n",
      "Dropped: 6319 (20, 27)\n",
      "Dropped: 6366 (20, 54)\n",
      "Dropped: 6384 (20, 97)\n",
      "Dropped: 6395 (20, 89)\n",
      "Dropped: 6406 (20, 78)\n",
      "Dropped: 6408 (20, 97)\n",
      "Dropped: 6410 (20, 80)\n",
      "Dropped: 6428 (20, 78)\n",
      "Dropped: 6446 (20, 87)\n",
      "Dropped: 6448 (20, 92)\n",
      "Dropped: 6452 (20, 50)\n",
      "Dropped: 6454 (20, 84)\n",
      "Dropped: 6456 (20, 74)\n",
      "Dropped: 6483 (20, 78)\n",
      "Dropped: 6495 (20, 59)\n",
      "Dropped: 6496 (20, 73)\n",
      "Dropped: 6501 (20, 76)\n",
      "Dropped: 6508 (20, 87)\n",
      "Dropped: 6544 (20, 84)\n",
      "Dropped: 6579 (20, 74)\n",
      "Dropped: 6588 (20, 97)\n",
      "Dropped: 6604 (20, 73)\n",
      "Dropped: 6608 (20, 80)\n",
      "Dropped: 6610 (20, 84)\n",
      "Dropped: 6649 (20, 84)\n",
      "Dropped: 6654 (20, 74)\n",
      "Dropped: 6658 (20, 92)\n",
      "Dropped: 6698 (20, 72)\n",
      "Dropped: 6702 (20, 97)\n",
      "Dropped: 6733 (20, 97)\n",
      "Dropped: 6736 (20, 93)\n",
      "Dropped: 6738 (20, 76)\n",
      "Dropped: 6750 (20, 54)\n",
      "Dropped: 6773 (20, 80)\n",
      "Dropped: 6792 (20, 83)\n",
      "Dropped: 6824 (20, 83)\n",
      "Dropped: 6832 (20, 59)\n",
      "Dropped: 6841 (20, 78)\n",
      "Dropped: 6845 (20, 74)\n",
      "Dropped: 6849 (20, 73)\n",
      "Dropped: 6864 (20, 87)\n",
      "Dropped: 6886 (20, 78)\n",
      "Dropped: 6897 (20, 89)\n",
      "Dropped: 6898 (20, 59)\n",
      "Dropped: 6902 (20, 97)\n",
      "Dropped: 6917 (20, 59)\n",
      "Dropped: 6921 (20, 93)\n",
      "Dropped: 6951 (20, 74)\n",
      "Dropped: 6953 (20, 97)\n",
      "Dropped: 6955 (20, 92)\n",
      "Dropped: 6972 (20, 97)\n",
      "Dropped: 7014 (20, 84)\n",
      "Dropped: 7022 (20, 93)\n",
      "Dropped: 7028 (20, 97)\n",
      "Dropped: 7032 (20, 97)\n",
      "Dropped: 7042 (20, 97)\n",
      "Dropped: 7046 (20, 74)\n",
      "Dropped: 7054 (20, 76)\n",
      "Dropped: 7055 (20, 74)\n",
      "Dropped: 7057 (20, 59)\n",
      "Dropped: 7063 (20, 76)\n",
      "Dropped: 7071 (20, 93)\n",
      "Dropped: 7074 (20, 89)\n",
      "Dropped: 7082 (20, 97)\n",
      "Dropped: 7095 (20, 74)\n",
      "Dropped: 7106 (20, 55)\n",
      "Dropped: 7136 (20, 97)\n",
      "Dropped: 7140 (20, 87)\n",
      "Dropped: 7148 (20, 74)\n",
      "Dropped: 7161 (20, 84)\n",
      "Dropped: 7171 (20, 93)\n",
      "Dropped: 7192 (20, 73)\n",
      "Dropped: 7202 (20, 97)\n",
      "Dropped: 7206 (20, 74)\n",
      "Dropped: 7214 (20, 72)\n",
      "Dropped: 7232 (20, 97)\n",
      "Dropped: 7238 (20, 75)\n",
      "Dropped: 7239 (20, 72)\n",
      "Dropped: 7281 (20, 92)\n",
      "Dropped: 7296 (20, 59)\n",
      "Dropped: 7299 (20, 75)\n",
      "Dropped: 7310 (20, 54)\n",
      "Dropped: 7317 (20, 84)\n",
      "Dropped: 7321 (20, 92)\n",
      "Dropped: 7322 (20, 97)\n",
      "Dropped: 7328 (20, 72)\n",
      "Dropped: 7332 (20, 50)\n",
      "Dropped: 7333 (20, 64)\n",
      "Dropped: 7334 (20, 93)\n",
      "Dropped: 7335 (20, 92)\n",
      "Dropped: 7359 (20, 78)\n",
      "Dropped: 7361 (20, 97)\n",
      "Dropped: 7378 (20, 54)\n",
      "Dropped: 7380 (20, 74)\n",
      "Dropped: 7421 (20, 93)\n",
      "Dropped: 7423 (20, 72)\n",
      "Dropped: 7428 (20, 83)\n",
      "Dropped: 7429 (20, 75)\n",
      "Dropped: 7457 (20, 87)\n",
      "Dropped: 7462 (20, 97)\n",
      "Dropped: 7478 (20, 89)\n",
      "Dropped: 7481 (20, 80)\n",
      "Dropped: 7511 (20, 76)\n",
      "Dropped: 7566 (20, 92)\n",
      "Dropped: 7568 (20, 92)\n",
      "Dropped: 7583 (20, 69)\n",
      "Dropped: 7590 (20, 87)\n",
      "Dropped: 7607 (20, 97)\n",
      "Dropped: 7619 (20, 84)\n",
      "Dropped: 7620 (20, 89)\n",
      "Dropped: 7632 (20, 74)\n",
      "Dropped: 7635 (20, 64)\n",
      "Dropped: 7650 (20, 50)\n",
      "Dropped: 7661 (20, 50)\n",
      "Dropped: 7696 (20, 97)\n",
      "Dropped: 7697 (20, 97)\n",
      "Dropped: 7699 (20, 74)\n",
      "Dropped: 7747 (20, 78)\n",
      "Dropped: 7757 (20, 84)\n",
      "Dropped: 7759 (20, 87)\n",
      "Dropped: 7762 (20, 93)\n",
      "Dropped: 7786 (20, 97)\n",
      "Dropped: 7796 (20, 76)\n",
      "Dropped: 7807 (20, 74)\n",
      "Dropped: 7810 (20, 73)\n",
      "Dropped: 7826 (20, 76)\n",
      "Dropped: 7838 (20, 97)\n",
      "Dropped: 7845 (20, 59)\n",
      "Dropped: 7848 (20, 69)\n",
      "Dropped: 7849 (20, 80)\n",
      "Dropped: 7850 (20, 73)\n",
      "Dropped: 7881 (20, 72)\n",
      "Dropped: 7898 (20, 97)\n",
      "Dropped: 7910 (20, 69)\n",
      "Dropped: 7920 (20, 42)\n",
      "Dropped: 7925 (20, 92)\n",
      "Dropped: 7927 (20, 63)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 7944 (20, 97)\n",
      "Dropped: 7952 (20, 78)\n",
      "Dropped: 7965 (20, 89)\n",
      "Dropped: 7967 (20, 67)\n",
      "Dropped: 7968 (20, 73)\n",
      "Dropped: 7969 (20, 74)\n",
      "Dropped: 7978 (20, 84)\n",
      "Dropped: 7982 (20, 87)\n",
      "Dropped: 8001 (20, 63)\n",
      "Dropped: 8005 (20, 63)\n",
      "Dropped: 8023 (20, 72)\n",
      "Dropped: 8044 (20, 59)\n",
      "Dropped: 8103 (20, 69)\n",
      "Dropped: 8115 (20, 97)\n",
      "Dropped: 8147 (20, 73)\n",
      "Dropped: 8159 (20, 97)\n",
      "Dropped: 8164 (20, 87)\n",
      "Dropped: 8175 (20, 87)\n",
      "Dropped: 8177 (20, 97)\n",
      "Dropped: 8185 (20, 89)\n",
      "Dropped: 8189 (20, 55)\n",
      "Dropped: 8211 (20, 54)\n",
      "Dropped: 8226 (20, 97)\n",
      "Dropped: 8232 (20, 59)\n",
      "Dropped: 8236 (20, 64)\n",
      "Dropped: 8241 (20, 59)\n",
      "Dropped: 8243 (20, 93)\n",
      "Dropped: 8251 (20, 76)\n",
      "Dropped: 8299 (20, 78)\n",
      "Dropped: 8312 (20, 89)\n",
      "Dropped: 8327 (20, 92)\n",
      "Dropped: 8328 (20, 93)\n",
      "Dropped: 8373 (20, 67)\n",
      "Dropped: 8375 (20, 72)\n",
      "Dropped: 8376 (20, 64)\n",
      "Dropped: 8382 (20, 84)\n",
      "Dropped: 8392 (20, 84)\n",
      "Dropped: 8403 (20, 93)\n",
      "Dropped: 8420 (20, 97)\n",
      "Dropped: 8424 (20, 93)\n",
      "Dropped: 8429 (20, 97)\n",
      "Dropped: 8432 (20, 69)\n",
      "Dropped: 8435 (20, 54)\n",
      "Dropped: 8463 (20, 42)\n",
      "Dropped: 8473 (20, 92)\n",
      "Dropped: 8493 (20, 84)\n",
      "Dropped: 8496 (20, 74)\n",
      "Dropped: 8507 (20, 84)\n",
      "Dropped: 8513 (20, 97)\n",
      "Dropped: 8534 (20, 73)\n",
      "Dropped: 8563 (20, 78)\n",
      "Dropped: 8572 (20, 93)\n",
      "Dropped: 8581 (20, 89)\n",
      "Dropped: 8588 (20, 54)\n",
      "Dropped: 8590 (20, 51)\n",
      "Dropped: 8601 (20, 72)\n",
      "Dropped: 8625 (20, 83)\n",
      "Dropped: 8626 (20, 97)\n",
      "Dropped: 8633 (20, 69)\n",
      "Dropped: 8638 (20, 93)\n",
      "Dropped: 8643 (20, 92)\n",
      "Dropped: 8645 (20, 75)\n",
      "Dropped: 8658 (20, 89)\n",
      "Dropped: 8666 (20, 80)\n",
      "Dropped: 8667 (20, 54)\n",
      "Dropped: 8685 (20, 93)\n",
      "Dropped: 8721 (20, 97)\n",
      "Dropped: 8722 (20, 76)\n",
      "Dropped: 8738 (20, 97)\n",
      "Dropped: 8749 (20, 74)\n",
      "Dropped: 8757 (20, 72)\n",
      "Dropped: 8758 (20, 73)\n",
      "Dropped: 8765 (20, 74)\n",
      "Dropped: 8767 (20, 93)\n",
      "Dropped: 8770 (20, 78)\n",
      "Dropped: 8787 (20, 92)\n",
      "Dropped: 8789 (20, 69)\n",
      "Dropped: 8794 (20, 76)\n",
      "Dropped: 8795 (20, 84)\n",
      "Dropped: 8797 (20, 54)\n",
      "Dropped: 8804 (20, 76)\n",
      "Dropped: 8833 (20, 97)\n",
      "Dropped: 8835 (20, 89)\n",
      "Dropped: 8843 (20, 55)\n",
      "Dropped: 8845 (20, 75)\n",
      "Dropped: 8848 (20, 97)\n",
      "Dropped: 8878 (20, 74)\n",
      "Dropped: 8880 (20, 83)\n",
      "Dropped: 8882 (20, 97)\n",
      "Dropped: 8885 (20, 92)\n",
      "Dropped: 8902 (20, 97)\n",
      "Dropped: 8909 (20, 89)\n",
      "Dropped: 8928 (20, 75)\n",
      "Dropped: 8938 (20, 59)\n",
      "Dropped: 8952 (20, 83)\n",
      "Dropped: 8961 (20, 75)\n",
      "Dropped: 8965 (20, 97)\n",
      "Dropped: 8974 (20, 87)\n",
      "Dropped: 8994 (20, 64)\n",
      "Dropped: 8999 (20, 67)\n",
      "Dropped: 9002 (20, 89)\n",
      "Dropped: 9004 (20, 92)\n",
      "Dropped: 9005 (20, 97)\n",
      "Dropped: 9006 (20, 74)\n",
      "Dropped: 9018 (20, 83)\n",
      "Dropped: 9036 (20, 78)\n",
      "Dropped: 9041 (20, 83)\n",
      "Dropped: 9045 (20, 92)\n",
      "Dropped: 9057 (20, 97)\n",
      "Dropped: 9065 (20, 84)\n",
      "Dropped: 9077 (20, 72)\n",
      "Dropped: 9078 (20, 73)\n",
      "Dropped: 9081 (20, 54)\n",
      "Dropped: 9097 (20, 84)\n",
      "Dropped: 9101 (20, 76)\n",
      "Dropped: 9132 (20, 89)\n",
      "Dropped: 9133 (20, 93)\n",
      "Dropped: 9143 (20, 46)\n",
      "Dropped: 9151 (20, 97)\n",
      "Dropped: 9155 (20, 97)\n",
      "Dropped: 9170 (20, 89)\n",
      "Dropped: 9171 (20, 97)\n",
      "Dropped: 9180 (20, 84)\n",
      "Dropped: 9191 (20, 87)\n",
      "Dropped: 9197 (20, 74)\n",
      "Dropped: 9199 (20, 84)\n",
      "Dropped: 9208 (20, 92)\n",
      "Dropped: 9211 (20, 65)\n",
      "Dropped: 9231 (20, 87)\n",
      "Dropped: 9234 (20, 72)\n",
      "Dropped: 9240 (20, 93)\n",
      "Dropped: 9263 (20, 89)\n",
      "Dropped: 9268 (20, 73)\n",
      "Dropped: 9269 (20, 74)\n",
      "Dropped: 9270 (20, 97)\n",
      "Dropped: 9274 (20, 97)\n",
      "Dropped: 9301 (20, 97)\n",
      "Dropped: 9303 (20, 63)\n",
      "Dropped: 9315 (20, 93)\n",
      "Dropped: 9327 (20, 76)\n",
      "Dropped: 9334 (20, 97)\n",
      "Dropped: 9351 (20, 87)\n",
      "Dropped: 9373 (20, 83)\n",
      "Dropped: 9375 (20, 63)\n",
      "Dropped: 9398 (20, 69)\n",
      "Dropped: 9400 (20, 93)\n",
      "Dropped: 9432 (20, 89)\n",
      "Dropped: 9490 (20, 67)\n",
      "Dropped: 9520 (20, 92)\n",
      "Dropped: 9521 (20, 97)\n",
      "Dropped: 9526 (20, 72)\n",
      "Dropped: 9530 (20, 89)\n",
      "Dropped: 9557 (20, 84)\n",
      "Dropped: 9577 (20, 76)\n",
      "Dropped: 9599 (20, 97)\n",
      "Dropped: 9606 (20, 93)\n",
      "Dropped: 9607 (20, 55)\n",
      "Dropped: 9614 (20, 93)\n",
      "Dropped: 9648 (20, 93)\n",
      "Dropped: 9657 (20, 76)\n",
      "Dropped: 9661 (20, 89)\n",
      "Dropped: 9670 (20, 87)\n",
      "Dropped: 9671 (20, 84)\n",
      "Dropped: 9674 (20, 74)\n",
      "Dropped: 9677 (20, 92)\n",
      "Dropped: 9712 (20, 72)\n",
      "Dropped: 9713 (20, 87)\n",
      "Dropped: 9721 (20, 33)\n",
      "Dropped: 9732 (20, 73)\n",
      "Dropped: 9739 (20, 83)\n",
      "Dropped: 9759 (20, 67)\n",
      "Dropped: 9763 (20, 67)\n",
      "Dropped: 9771 (20, 80)\n",
      "Dropped: 9779 (20, 91)\n",
      "Dropped: 9787 (20, 93)\n",
      "Dropped: 9793 (20, 89)\n",
      "Dropped: 9795 (20, 97)\n",
      "Dropped: 9802 (20, 46)\n",
      "Dropped: 9809 (20, 67)\n",
      "Dropped: 9810 (20, 92)\n",
      "Dropped: 9812 (20, 74)\n",
      "Dropped: 9813 (20, 50)\n",
      "Dropped: 9814 (20, 93)\n",
      "Dropped: 9831 (20, 87)\n",
      "Dropped: 9891 (20, 67)\n",
      "Dropped: 9905 (20, 67)\n",
      "Dropped: 9912 (20, 93)\n",
      "Dropped: 9914 (20, 84)\n",
      "Dropped: 9916 (20, 74)\n",
      "Dropped: 9960 (20, 92)\n",
      "Dropped: 9963 (20, 89)\n",
      "Dropped: 9969 (20, 67)\n",
      "Dropped: 9999 (20, 74)\n",
      "Dropped: 10000 (20, 59)\n",
      "Dropped: 10002 (20, 80)\n",
      "Dropped: 10017 (20, 84)\n",
      "Dropped: 10045 (20, 89)\n",
      "Dropped: 10055 (20, 97)\n",
      "Dropped: 10069 (20, 59)\n",
      "Dropped: 10075 (20, 87)\n",
      "Dropped: 10083 (20, 50)\n",
      "Dropped: 10090 (20, 59)\n",
      "Dropped: 10099 (20, 54)\n",
      "Dropped: 10103 (20, 50)\n",
      "Dropped: 10118 (20, 74)\n",
      "Dropped: 10121 (20, 84)\n",
      "Dropped: 10127 (20, 97)\n",
      "Dropped: 10131 (20, 80)\n",
      "Dropped: 10134 (20, 95)\n",
      "Dropped: 10149 (20, 64)\n",
      "Dropped: 10151 (20, 50)\n",
      "Dropped: 10164 (20, 80)\n",
      "Dropped: 10193 (20, 89)\n",
      "Dropped: 10212 (20, 97)\n",
      "Dropped: 10225 (20, 54)\n",
      "Dropped: 10232 (20, 78)\n",
      "Dropped: 10245 (20, 89)\n",
      "Dropped: 10247 (20, 72)\n",
      "Dropped: 10250 (20, 89)\n",
      "Dropped: 10281 (20, 83)\n",
      "Dropped: 10299 (20, 72)\n",
      "Dropped: 10301 (20, 77)\n",
      "Dropped: 10305 (20, 92)\n",
      "Dropped: 10307 (20, 84)\n",
      "Dropped: 10326 (20, 69)\n",
      "Dropped: 10340 (20, 87)\n",
      "Dropped: 10341 (20, 80)\n",
      "Dropped: 10343 (20, 75)\n",
      "Dropped: 10367 (20, 50)\n",
      "Dropped: 10378 (20, 97)\n",
      "Dropped: 10391 (20, 72)\n",
      "Dropped: 10405 (20, 97)\n",
      "Dropped: 10410 (20, 97)\n",
      "Dropped: 10419 (20, 76)\n",
      "Dropped: 10428 (20, 54)\n",
      "Dropped: 10454 (20, 89)\n",
      "Dropped: 10467 (20, 63)\n",
      "Dropped: 10491 (20, 97)\n",
      "Dropped: 10500 (20, 87)\n",
      "Dropped: 10506 (20, 75)\n",
      "Dropped: 10532 (20, 93)\n",
      "Dropped: 10534 (20, 80)\n",
      "Dropped: 10542 (20, 89)\n",
      "Dropped: 10547 (20, 89)\n",
      "Dropped: 10552 (20, 54)\n",
      "Dropped: 10573 (20, 84)\n",
      "Dropped: 10580 (20, 74)\n",
      "Dropped: 10591 (20, 80)\n",
      "Dropped: 10594 (20, 84)\n",
      "Dropped: 10599 (20, 87)\n",
      "Dropped: 10619 (20, 84)\n",
      "Dropped: 10636 (20, 93)\n",
      "Dropped: 10641 (20, 54)\n",
      "Dropped: 10654 (20, 69)\n",
      "Dropped: 10655 (20, 73)\n",
      "Dropped: 10664 (20, 74)\n",
      "Dropped: 10665 (20, 83)\n",
      "Dropped: 10679 (20, 63)\n",
      "Dropped: 10687 (20, 89)\n",
      "Dropped: 10690 (20, 77)\n",
      "Dropped: 10692 (20, 63)\n",
      "Dropped: 10710 (20, 63)\n",
      "Dropped: 10758 (20, 83)\n",
      "Dropped: 10763 (20, 87)\n",
      "Dropped: 10765 (20, 83)\n",
      "Dropped: 10781 (20, 69)\n",
      "Dropped: 10782 (20, 89)\n",
      "Dropped: 10806 (20, 97)\n",
      "Dropped: 10807 (20, 92)\n",
      "Dropped: 10809 (20, 89)\n",
      "Dropped: 10820 (20, 92)\n",
      "Dropped: 10824 (20, 69)\n",
      "Dropped: 10827 (20, 73)\n",
      "Dropped: 10863 (20, 64)\n",
      "Dropped: 10880 (20, 95)\n",
      "Dropped: 10881 (20, 45)\n",
      "Dropped: 10885 (20, 80)\n",
      "Dropped: 10886 (20, 97)\n",
      "Dropped: 10900 (20, 59)\n",
      "Dropped: 10927 (20, 59)\n",
      "Dropped: 10928 (20, 97)\n",
      "Dropped: 10932 (20, 89)\n",
      "Dropped: 10934 (20, 74)\n",
      "Dropped: 10938 (20, 93)\n",
      "Dropped: 10947 (20, 76)\n",
      "Dropped: 10949 (20, 59)\n",
      "Dropped: 10952 (20, 97)\n",
      "Dropped: 10954 (20, 89)\n",
      "Dropped: 10974 (20, 59)\n",
      "Dropped: 10983 (20, 89)\n",
      "Dropped: 10988 (20, 92)\n",
      "Dropped: 10997 (20, 92)\n",
      "Dropped: 11002 (20, 93)\n",
      "Dropped: 11007 (20, 76)\n",
      "Dropped: 11028 (20, 73)\n",
      "Dropped: 11038 (20, 84)\n",
      "Dropped: 11053 (20, 97)\n",
      "Dropped: 11055 (20, 97)\n",
      "Dropped: 11056 (20, 77)\n",
      "Dropped: 11059 (20, 84)\n",
      "Dropped: 11098 (20, 93)\n",
      "Dropped: 11103 (20, 73)\n",
      "Dropped: 11110 (20, 83)\n",
      "Dropped: 11118 (20, 78)\n",
      "Dropped: 11122 (20, 92)\n",
      "Dropped: 11125 (20, 93)\n",
      "Dropped: 11153 (20, 97)\n",
      "Dropped: 11175 (20, 73)\n",
      "Dropped: 11178 (20, 78)\n",
      "Dropped: 11192 (20, 54)\n",
      "Dropped: 11195 (20, 97)\n",
      "Dropped: 11202 (20, 72)\n",
      "Dropped: 11208 (20, 67)\n",
      "Dropped: 11212 (20, 54)\n",
      "Dropped: 11251 (20, 63)\n",
      "Dropped: 11258 (20, 54)\n",
      "Dropped: 11278 (20, 76)\n",
      "Dropped: 11286 (20, 84)\n",
      "Dropped: 11303 (20, 93)\n",
      "Dropped: 11308 (20, 89)\n",
      "Dropped: 11311 (20, 75)\n",
      "Dropped: 11314 (20, 84)\n",
      "Dropped: 11328 (20, 83)\n",
      "Dropped: 11349 (20, 89)\n",
      "Dropped: 11350 (20, 89)\n",
      "Dropped: 11352 (20, 76)\n",
      "Dropped: 11354 (20, 50)\n",
      "Dropped: 11357 (20, 59)\n",
      "Dropped: 11385 (20, 84)\n",
      "Dropped: 11386 (20, 93)\n",
      "Dropped: 11396 (20, 67)\n",
      "Dropped: 11399 (20, 97)\n",
      "Dropped: 11414 (20, 67)\n",
      "Dropped: 11417 (20, 80)\n",
      "Dropped: 11421 (20, 67)\n",
      "Dropped: 11423 (20, 63)\n",
      "Dropped: 11433 (20, 73)\n",
      "Dropped: 11443 (20, 75)\n",
      "Dropped: 11446 (20, 54)\n",
      "Dropped: 11451 (20, 59)\n",
      "Dropped: 11459 (20, 69)\n",
      "Dropped: 11468 (20, 97)\n",
      "Dropped: 11471 (20, 89)\n",
      "Dropped: 11487 (20, 97)\n",
      "Dropped: 11494 (20, 87)\n",
      "Dropped: 11520 (20, 74)\n",
      "Dropped: 11533 (20, 80)\n",
      "Dropped: 11536 (20, 92)\n",
      "Dropped: 11541 (20, 74)\n",
      "Dropped: 11545 (20, 97)\n",
      "Dropped: 11551 (20, 97)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 11559 (20, 97)\n",
      "Dropped: 11569 (20, 97)\n",
      "Dropped: 11572 (20, 55)\n",
      "Dropped: 11574 (20, 76)\n",
      "Dropped: 11584 (20, 63)\n",
      "Dropped: 11601 (20, 69)\n",
      "Dropped: 11624 (20, 87)\n",
      "Dropped: 11634 (20, 97)\n",
      "Dropped: 11637 (20, 69)\n",
      "Dropped: 11656 (20, 78)\n",
      "Dropped: 11668 (20, 69)\n",
      "Dropped: 11674 (20, 83)\n",
      "Dropped: 11686 (20, 72)\n",
      "Dropped: 11689 (20, 80)\n",
      "Dropped: 11690 (20, 55)\n",
      "Dropped: 11691 (20, 74)\n",
      "Dropped: 11711 (20, 74)\n",
      "Dropped: 11716 (20, 97)\n",
      "Dropped: 11738 (20, 93)\n",
      "Dropped: 11745 (20, 80)\n",
      "Dropped: 11748 (20, 87)\n",
      "Dropped: 11770 (20, 73)\n",
      "Dropped: 11785 (20, 80)\n",
      "Dropped: 11795 (20, 83)\n",
      "Dropped: 11800 (20, 72)\n",
      "Dropped: 11806 (20, 84)\n",
      "Dropped: 11808 (20, 87)\n",
      "Dropped: 11809 (20, 83)\n",
      "Dropped: 11821 (20, 97)\n",
      "Dropped: 11822 (20, 87)\n",
      "Dropped: 11843 (20, 63)\n",
      "Dropped: 11844 (20, 89)\n",
      "Dropped: 11861 (20, 75)\n",
      "Dropped: 11882 (20, 55)\n",
      "Dropped: 11889 (20, 64)\n",
      "Dropped: 11895 (20, 74)\n",
      "Dropped: 11904 (20, 84)\n",
      "Dropped: 11918 (20, 97)\n",
      "Dropped: 11926 (20, 89)\n",
      "Dropped: 11936 (20, 83)\n",
      "Dropped: 11952 (20, 76)\n",
      "Dropped: 12016 (20, 97)\n",
      "Dropped: 12029 (20, 74)\n",
      "Dropped: 12031 (20, 74)\n",
      "Dropped: 12036 (20, 93)\n",
      "Dropped: 12047 (20, 97)\n",
      "Dropped: 12052 (20, 72)\n",
      "Dropped: 12059 (20, 83)\n",
      "Dropped: 12074 (20, 97)\n",
      "Dropped: 12086 (20, 69)\n",
      "Dropped: 12102 (20, 69)\n",
      "Dropped: 12111 (20, 97)\n",
      "Dropped: 12119 (20, 87)\n",
      "Dropped: 12130 (20, 78)\n",
      "Dropped: 12140 (20, 55)\n",
      "Dropped: 12151 (20, 93)\n",
      "Dropped: 12160 (20, 93)\n",
      "Dropped: 12171 (20, 89)\n",
      "Dropped: 12178 (20, 80)\n",
      "Dropped: 12187 (20, 67)\n",
      "Dropped: 12192 (20, 72)\n",
      "Dropped: 12206 (20, 76)\n",
      "Dropped: 12208 (20, 72)\n",
      "Dropped: 12224 (20, 97)\n",
      "Dropped: 12234 (20, 78)\n",
      "Dropped: 12270 (20, 67)\n",
      "Dropped: 12317 (20, 92)\n",
      "Dropped: 12327 (20, 74)\n",
      "Dropped: 12332 (20, 97)\n",
      "Dropped: 12350 (20, 87)\n",
      "Dropped: 12358 (20, 80)\n",
      "Dropped: 12359 (20, 80)\n",
      "Dropped: 12366 (20, 84)\n",
      "Dropped: 12379 (20, 78)\n",
      "Dropped: 12383 (20, 83)\n",
      "Dropped: 12386 (20, 89)\n",
      "Dropped: 12395 (20, 97)\n",
      "Dropped: 12412 (20, 67)\n",
      "Dropped: 12434 (20, 59)\n",
      "Dropped: 12438 (20, 76)\n",
      "Dropped: 12490 (20, 63)\n",
      "Dropped: 12497 (20, 78)\n",
      "Dropped: 12500 (20, 55)\n",
      "Dropped: 12513 (20, 63)\n",
      "Dropped: 12518 (20, 74)\n",
      "Dropped: 12530 (20, 76)\n",
      "Dropped: 12541 (20, 93)\n",
      "Dropped: 12543 (20, 92)\n",
      "Dropped: 12563 (20, 67)\n",
      "Dropped: 12584 (20, 83)\n",
      "Dropped: 12610 (20, 97)\n",
      "Dropped: 12614 (20, 74)\n",
      "Dropped: 12642 (20, 76)\n",
      "Dropped: 12655 (20, 81)\n",
      "Dropped: 12664 (20, 78)\n",
      "Dropped: 12665 (20, 83)\n",
      "Dropped: 12666 (20, 89)\n",
      "Dropped: 12673 (20, 93)\n",
      "Dropped: 12674 (20, 89)\n",
      "Dropped: 12686 (20, 78)\n",
      "Dropped: 12688 (20, 93)\n",
      "Dropped: 12693 (20, 55)\n",
      "Dropped: 12708 (20, 80)\n",
      "Dropped: 12711 (20, 67)\n",
      "Dropped: 12715 (20, 97)\n",
      "Dropped: 12716 (20, 64)\n",
      "Dropped: 12718 (20, 97)\n",
      "Dropped: 12731 (20, 67)\n",
      "Dropped: 12748 (20, 54)\n",
      "Dropped: 12751 (20, 63)\n",
      "Dropped: 12778 (20, 84)\n",
      "Dropped: 12789 (20, 89)\n",
      "Dropped: 12795 (20, 93)\n",
      "Dropped: 12798 (20, 50)\n",
      "Dropped: 12810 (20, 79)\n",
      "Dropped: 12812 (20, 59)\n",
      "Dropped: 12820 (20, 97)\n",
      "Dropped: 12824 (20, 63)\n",
      "Dropped: 12825 (20, 97)\n",
      "Dropped: 12830 (20, 93)\n",
      "Dropped: 12838 (20, 97)\n",
      "Dropped: 12842 (20, 67)\n",
      "Dropped: 12843 (20, 72)\n",
      "Dropped: 12878 (20, 93)\n",
      "Dropped: 12885 (20, 76)\n",
      "Dropped: 12900 (20, 89)\n",
      "Dropped: 12914 (20, 97)\n",
      "Dropped: 12929 (20, 74)\n",
      "Dropped: 12935 (20, 72)\n",
      "Dropped: 12979 (20, 97)\n",
      "Dropped: 13018 (20, 74)\n",
      "Dropped: 13029 (20, 75)\n",
      "Dropped: 13052 (20, 97)\n",
      "Dropped: 13071 (20, 89)\n",
      "Dropped: 13072 (20, 97)\n",
      "Dropped: 13088 (20, 80)\n",
      "Dropped: 13098 (20, 97)\n",
      "Dropped: 13099 (20, 74)\n",
      "Dropped: 13116 (20, 97)\n",
      "Dropped: 13130 (20, 74)\n",
      "Dropped: 13140 (20, 73)\n",
      "Dropped: 13148 (20, 87)\n",
      "Dropped: 13169 (20, 74)\n",
      "Dropped: 13203 (20, 97)\n",
      "Dropped: 13205 (20, 72)\n",
      "Dropped: 13206 (20, 89)\n",
      "Dropped: 13230 (20, 81)\n",
      "Dropped: 13237 (20, 87)\n",
      "Dropped: 13241 (20, 89)\n",
      "Dropped: 13268 (20, 72)\n",
      "Dropped: 13271 (20, 93)\n",
      "Dropped: 13279 (20, 87)\n",
      "Dropped: 13289 (20, 93)\n",
      "Dropped: 13291 (20, 72)\n",
      "Dropped: 13301 (20, 76)\n",
      "Dropped: 13309 (20, 93)\n",
      "Dropped: 13313 (20, 73)\n",
      "Dropped: 13314 (20, 78)\n",
      "Dropped: 13325 (20, 75)\n",
      "Dropped: 13341 (20, 93)\n",
      "Dropped: 13368 (20, 96)\n",
      "Dropped: 13397 (20, 93)\n",
      "Dropped: 13406 (20, 80)\n",
      "Dropped: 13409 (20, 84)\n",
      "Dropped: 13410 (20, 76)\n",
      "Dropped: 13414 (20, 56)\n",
      "Dropped: 13436 (20, 80)\n",
      "Dropped: 13439 (20, 67)\n",
      "Dropped: 13453 (20, 80)\n",
      "Dropped: 13455 (20, 97)\n",
      "Dropped: 13470 (20, 42)\n",
      "Dropped: 13476 (20, 76)\n",
      "Dropped: 13477 (20, 76)\n",
      "Dropped: 13499 (20, 72)\n",
      "Dropped: 13513 (20, 50)\n",
      "Dropped: 13515 (20, 93)\n",
      "Dropped: 13517 (20, 83)\n",
      "Dropped: 13519 (20, 63)\n",
      "Dropped: 13527 (20, 80)\n",
      "Dropped: 13541 (20, 69)\n",
      "Dropped: 13544 (20, 73)\n",
      "Dropped: 13556 (20, 64)\n",
      "Dropped: 13562 (20, 93)\n",
      "Dropped: 13580 (20, 84)\n",
      "Dropped: 13596 (20, 92)\n",
      "Dropped: 13599 (20, 55)\n",
      "Dropped: 13607 (20, 93)\n",
      "Dropped: 13624 (20, 55)\n",
      "Dropped: 13637 (20, 73)\n",
      "Dropped: 13645 (20, 97)\n",
      "Dropped: 13646 (20, 74)\n",
      "Dropped: 13654 (20, 87)\n",
      "Dropped: 13695 (20, 87)\n",
      "Dropped: 13699 (20, 74)\n",
      "Dropped: 13706 (20, 97)\n",
      "Dropped: 13707 (20, 80)\n",
      "Dropped: 13720 (20, 85)\n",
      "Dropped: 13746 (20, 67)\n",
      "Dropped: 13780 (20, 72)\n",
      "Dropped: 13814 (20, 92)\n",
      "Dropped: 13826 (20, 84)\n",
      "Dropped: 13842 (20, 54)\n",
      "Dropped: 13866 (20, 92)\n",
      "Dropped: 13871 (20, 87)\n",
      "Dropped: 13877 (20, 72)\n",
      "Dropped: 13909 (20, 92)\n",
      "Dropped: 13922 (20, 67)\n",
      "Dropped: 13923 (20, 87)\n",
      "Dropped: 13926 (20, 74)\n",
      "Dropped: 13928 (20, 83)\n",
      "Dropped: 13959 (20, 83)\n",
      "Dropped: 13969 (20, 97)\n",
      "Dropped: 13973 (20, 97)\n",
      "Dropped: 13974 (20, 92)\n",
      "Dropped: 13982 (20, 92)\n",
      "Dropped: 13993 (20, 84)\n",
      "Dropped: 14009 (20, 74)\n",
      "Dropped: 14015 (20, 84)\n",
      "Dropped: 14022 (20, 97)\n",
      "Dropped: 14025 (20, 74)\n",
      "Dropped: 14029 (20, 89)\n",
      "Dropped: 14030 (20, 80)\n",
      "Dropped: 14034 (20, 54)\n",
      "Dropped: 14045 (20, 97)\n",
      "Dropped: 14046 (20, 84)\n",
      "Dropped: 14054 (20, 89)\n",
      "Dropped: 14064 (20, 93)\n",
      "Dropped: 14078 (20, 75)\n",
      "Dropped: 14079 (20, 50)\n",
      "Dropped: 14116 (20, 74)\n",
      "Dropped: 14131 (20, 97)\n",
      "Dropped: 14132 (20, 80)\n",
      "Dropped: 14147 (20, 97)\n",
      "Dropped: 14161 (20, 87)\n",
      "Dropped: 14162 (20, 72)\n",
      "Dropped: 14188 (20, 74)\n",
      "Dropped: 14202 (20, 72)\n",
      "Dropped: 14222 (20, 63)\n",
      "Dropped: 14233 (20, 87)\n",
      "Dropped: 14236 (20, 74)\n",
      "Dropped: 14239 (20, 93)\n",
      "Dropped: 14262 (20, 59)\n",
      "Dropped: 14277 (20, 73)\n",
      "Dropped: 14285 (20, 42)\n",
      "Dropped: 14294 (20, 76)\n",
      "Dropped: 14302 (20, 93)\n",
      "Dropped: 14316 (20, 73)\n",
      "Dropped: 14327 (20, 59)\n",
      "Dropped: 14335 (20, 89)\n",
      "Dropped: 14346 (20, 93)\n",
      "Dropped: 14348 (20, 93)\n",
      "Dropped: 14357 (20, 75)\n",
      "Dropped: 14364 (20, 87)\n",
      "Dropped: 14368 (20, 97)\n",
      "Dropped: 14371 (20, 33)\n",
      "Dropped: 14377 (20, 78)\n",
      "Dropped: 14380 (20, 75)\n",
      "Dropped: 14405 (20, 75)\n",
      "Dropped: 14416 (20, 75)\n",
      "Dropped: 14423 (20, 50)\n",
      "Dropped: 14434 (20, 83)\n",
      "Dropped: 14438 (20, 89)\n",
      "Dropped: 14444 (20, 80)\n",
      "Dropped: 14479 (20, 80)\n",
      "Dropped: 14488 (20, 78)\n",
      "Dropped: 14498 (20, 76)\n",
      "Dropped: 14504 (20, 73)\n",
      "Dropped: 14506 (20, 87)\n",
      "Dropped: 14524 (20, 87)\n",
      "Dropped: 14525 (20, 73)\n",
      "Dropped: 14543 (20, 84)\n",
      "Dropped: 14587 (20, 76)\n",
      "Dropped: 14598 (20, 93)\n",
      "Dropped: 14614 (20, 97)\n",
      "Dropped: 14621 (20, 59)\n",
      "Dropped: 14623 (20, 80)\n",
      "Dropped: 14636 (20, 97)\n",
      "Dropped: 14638 (20, 97)\n",
      "Dropped: 14658 (20, 84)\n",
      "Dropped: 14667 (20, 89)\n",
      "Dropped: 14678 (20, 87)\n",
      "Dropped: 14684 (20, 92)\n",
      "Dropped: 14695 (20, 76)\n",
      "Dropped: 14710 (20, 76)\n",
      "Dropped: 14711 (20, 92)\n",
      "Dropped: 14719 (20, 93)\n",
      "Dropped: 14721 (20, 59)\n",
      "Dropped: 14728 (20, 97)\n",
      "Dropped: 14730 (20, 93)\n",
      "Dropped: 14734 (20, 74)\n",
      "Dropped: 14739 (20, 67)\n",
      "Dropped: 14767 (20, 89)\n",
      "Dropped: 14771 (20, 59)\n",
      "Dropped: 14775 (20, 78)\n",
      "Dropped: 14782 (20, 83)\n",
      "Dropped: 14784 (20, 72)\n",
      "Dropped: 14847 (20, 80)\n",
      "Dropped: 14859 (20, 54)\n",
      "Dropped: 14868 (20, 83)\n",
      "Dropped: 14880 (20, 92)\n",
      "Dropped: 14898 (20, 50)\n",
      "Dropped: 14902 (20, 72)\n",
      "Dropped: 14909 (20, 93)\n",
      "Dropped: 14913 (20, 92)\n",
      "Dropped: 14918 (20, 92)\n",
      "Dropped: 14926 (20, 92)\n",
      "Dropped: 14935 (20, 64)\n",
      "Dropped: 14945 (20, 74)\n",
      "Dropped: 14946 (20, 72)\n",
      "Dropped: 14969 (20, 84)\n",
      "Dropped: 14972 (20, 64)\n",
      "Dropped: 14974 (20, 92)\n",
      "Dropped: 14979 (20, 83)\n",
      "Dropped: 14984 (20, 80)\n",
      "Dropped: 14994 (20, 84)\n",
      "Dropped: 15010 (20, 97)\n",
      "Dropped: 15014 (20, 84)\n",
      "Dropped: 15025 (20, 93)\n",
      "Dropped: 15030 (20, 69)\n",
      "Dropped: 15032 (20, 80)\n",
      "Dropped: 15036 (20, 54)\n",
      "Dropped: 15042 (20, 59)\n",
      "Dropped: 15062 (20, 67)\n",
      "Dropped: 15068 (20, 78)\n",
      "Dropped: 15083 (20, 92)\n",
      "Dropped: 15106 (20, 72)\n",
      "Dropped: 15110 (20, 73)\n",
      "Dropped: 15113 (20, 97)\n",
      "Dropped: 15127 (20, 78)\n",
      "Dropped: 15129 (20, 97)\n",
      "Dropped: 15142 (20, 80)\n",
      "Dropped: 15143 (20, 72)\n",
      "Dropped: 15146 (20, 97)\n",
      "Dropped: 15166 (20, 76)\n",
      "Dropped: 15186 (20, 92)\n",
      "Dropped: 15191 (20, 93)\n",
      "Dropped: 15219 (20, 75)\n",
      "Dropped: 15227 (20, 89)\n",
      "Dropped: 15229 (20, 80)\n",
      "Dropped: 15235 (20, 84)\n",
      "Dropped: 15237 (20, 74)\n",
      "Dropped: 15238 (20, 93)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 15245 (20, 89)\n",
      "Dropped: 15251 (20, 87)\n",
      "Dropped: 15256 (20, 32)\n",
      "Removed percentage: 0.09299888663304735\n",
      "Dropped: 4 (20, 69)\n",
      "Dropped: 5 (20, 67)\n",
      "Dropped: 17 (20, 63)\n",
      "Dropped: 19 (20, 92)\n",
      "Dropped: 26 (20, 89)\n",
      "Dropped: 35 (20, 50)\n",
      "Dropped: 37 (20, 89)\n",
      "Dropped: 55 (20, 97)\n",
      "Dropped: 62 (20, 78)\n",
      "Dropped: 72 (20, 78)\n",
      "Dropped: 97 (20, 80)\n",
      "Dropped: 130 (20, 80)\n",
      "Dropped: 131 (20, 94)\n",
      "Dropped: 143 (20, 76)\n",
      "Dropped: 153 (20, 64)\n",
      "Dropped: 158 (20, 87)\n",
      "Dropped: 163 (20, 59)\n",
      "Dropped: 164 (20, 46)\n",
      "Dropped: 204 (20, 97)\n",
      "Dropped: 222 (20, 74)\n",
      "Dropped: 234 (20, 59)\n",
      "Dropped: 252 (20, 89)\n",
      "Dropped: 263 (20, 76)\n",
      "Dropped: 267 (20, 97)\n",
      "Dropped: 293 (20, 84)\n",
      "Dropped: 298 (20, 69)\n",
      "Dropped: 305 (20, 74)\n",
      "Dropped: 320 (20, 69)\n",
      "Dropped: 367 (20, 93)\n",
      "Dropped: 376 (20, 72)\n",
      "Dropped: 378 (20, 59)\n",
      "Dropped: 382 (20, 74)\n",
      "Dropped: 394 (20, 67)\n",
      "Dropped: 402 (20, 84)\n",
      "Dropped: 418 (20, 69)\n",
      "Dropped: 421 (20, 83)\n",
      "Dropped: 429 (20, 92)\n",
      "Dropped: 438 (20, 93)\n",
      "Dropped: 443 (20, 46)\n",
      "Dropped: 447 (20, 93)\n",
      "Dropped: 458 (20, 75)\n",
      "Dropped: 483 (20, 91)\n",
      "Dropped: 486 (20, 69)\n",
      "Dropped: 505 (20, 75)\n",
      "Dropped: 507 (20, 92)\n",
      "Dropped: 541 (20, 97)\n",
      "Dropped: 551 (20, 72)\n",
      "Dropped: 552 (20, 87)\n",
      "Dropped: 559 (20, 84)\n",
      "Dropped: 565 (20, 63)\n",
      "Dropped: 570 (20, 97)\n",
      "Dropped: 587 (20, 89)\n",
      "Dropped: 588 (20, 93)\n",
      "Dropped: 592 (20, 93)\n",
      "Dropped: 596 (20, 73)\n",
      "Dropped: 597 (20, 97)\n",
      "Dropped: 607 (20, 97)\n",
      "Dropped: 613 (20, 97)\n",
      "Dropped: 614 (20, 77)\n",
      "Dropped: 627 (20, 93)\n",
      "Dropped: 632 (20, 97)\n",
      "Dropped: 657 (20, 73)\n",
      "Dropped: 666 (20, 89)\n",
      "Dropped: 695 (20, 76)\n",
      "Dropped: 698 (20, 69)\n",
      "Dropped: 713 (20, 72)\n",
      "Dropped: 722 (20, 92)\n",
      "Dropped: 730 (20, 75)\n",
      "Dropped: 740 (20, 83)\n",
      "Dropped: 787 (20, 83)\n",
      "Dropped: 788 (20, 73)\n",
      "Dropped: 790 (20, 89)\n",
      "Dropped: 795 (20, 64)\n",
      "Dropped: 808 (20, 78)\n",
      "Dropped: 809 (20, 63)\n",
      "Dropped: 814 (20, 89)\n",
      "Dropped: 828 (20, 80)\n",
      "Dropped: 835 (20, 76)\n",
      "Dropped: 858 (20, 83)\n",
      "Dropped: 861 (20, 89)\n",
      "Dropped: 865 (20, 97)\n",
      "Dropped: 866 (20, 97)\n",
      "Dropped: 884 (20, 97)\n",
      "Dropped: 886 (20, 67)\n",
      "Dropped: 905 (20, 89)\n",
      "Dropped: 913 (20, 97)\n",
      "Dropped: 932 (20, 92)\n",
      "Dropped: 942 (20, 74)\n",
      "Dropped: 952 (20, 91)\n",
      "Dropped: 970 (20, 97)\n",
      "Dropped: 973 (20, 69)\n",
      "Dropped: 974 (20, 89)\n",
      "Dropped: 978 (20, 97)\n",
      "Dropped: 981 (20, 93)\n",
      "Dropped: 987 (20, 97)\n",
      "Dropped: 1023 (20, 89)\n",
      "Dropped: 1030 (20, 74)\n",
      "Dropped: 1041 (20, 64)\n",
      "Dropped: 1042 (20, 93)\n",
      "Dropped: 1045 (20, 76)\n",
      "Dropped: 1053 (20, 75)\n",
      "Dropped: 1068 (20, 59)\n",
      "Dropped: 1071 (20, 54)\n",
      "Dropped: 1079 (20, 92)\n",
      "Dropped: 1085 (20, 87)\n",
      "Dropped: 1093 (20, 93)\n",
      "Dropped: 1094 (20, 83)\n",
      "Dropped: 1096 (20, 93)\n",
      "Dropped: 1097 (20, 89)\n",
      "Dropped: 1110 (20, 37)\n",
      "Dropped: 1122 (20, 89)\n",
      "Dropped: 1130 (20, 97)\n",
      "Dropped: 1137 (20, 80)\n",
      "Dropped: 1148 (20, 92)\n",
      "Dropped: 1154 (20, 93)\n",
      "Dropped: 1159 (20, 87)\n",
      "Dropped: 1171 (20, 80)\n",
      "Dropped: 1175 (20, 72)\n",
      "Dropped: 1193 (20, 89)\n",
      "Dropped: 1195 (20, 97)\n",
      "Dropped: 1210 (20, 67)\n",
      "Dropped: 1228 (20, 87)\n",
      "Dropped: 1230 (20, 59)\n",
      "Dropped: 1270 (20, 97)\n",
      "Dropped: 1277 (20, 80)\n",
      "Dropped: 1280 (20, 89)\n",
      "Dropped: 1300 (20, 54)\n",
      "Dropped: 1311 (20, 74)\n",
      "Dropped: 1312 (20, 64)\n",
      "Dropped: 1330 (20, 69)\n",
      "Dropped: 1338 (20, 50)\n",
      "Dropped: 1340 (20, 83)\n",
      "Dropped: 1365 (20, 46)\n",
      "Dropped: 1367 (20, 92)\n",
      "Dropped: 1391 (20, 84)\n",
      "Dropped: 1394 (20, 89)\n",
      "Dropped: 1397 (20, 89)\n",
      "Dropped: 1398 (20, 69)\n",
      "Dropped: 1400 (20, 69)\n",
      "Dropped: 1418 (20, 76)\n",
      "Dropped: 1421 (20, 87)\n",
      "Dropped: 1424 (20, 97)\n",
      "Dropped: 1466 (20, 97)\n",
      "Dropped: 1467 (20, 89)\n",
      "Dropped: 1486 (20, 74)\n",
      "Dropped: 1492 (20, 97)\n",
      "Dropped: 1501 (20, 74)\n",
      "Dropped: 1505 (20, 68)\n",
      "Dropped: 1508 (20, 75)\n",
      "Dropped: 1513 (20, 73)\n",
      "Dropped: 1525 (20, 72)\n",
      "Dropped: 1538 (20, 78)\n",
      "Dropped: 1547 (20, 76)\n",
      "Dropped: 1550 (20, 93)\n",
      "Dropped: 1558 (20, 54)\n",
      "Dropped: 1565 (20, 50)\n",
      "Dropped: 1583 (20, 72)\n",
      "Dropped: 1595 (20, 74)\n",
      "Dropped: 1597 (20, 64)\n",
      "Dropped: 1615 (20, 97)\n",
      "Dropped: 1618 (20, 84)\n",
      "Dropped: 1622 (20, 64)\n",
      "Dropped: 1626 (20, 78)\n",
      "Dropped: 1627 (20, 74)\n",
      "Dropped: 1674 (20, 78)\n",
      "Dropped: 1677 (20, 63)\n",
      "Dropped: 1686 (20, 97)\n",
      "Dropped: 1693 (20, 72)\n",
      "Dropped: 1702 (20, 93)\n",
      "Dropped: 1708 (20, 97)\n",
      "Dropped: 1720 (20, 97)\n",
      "Dropped: 1723 (20, 74)\n",
      "Dropped: 1727 (20, 63)\n",
      "Dropped: 1732 (20, 80)\n",
      "Dropped: 1734 (20, 80)\n",
      "Dropped: 1736 (20, 69)\n",
      "Dropped: 1753 (20, 67)\n",
      "Dropped: 1763 (20, 57)\n",
      "Dropped: 1792 (20, 76)\n",
      "Dropped: 1805 (20, 69)\n",
      "Dropped: 1816 (20, 89)\n",
      "Dropped: 1830 (20, 97)\n",
      "Dropped: 1831 (20, 97)\n",
      "Dropped: 1838 (20, 83)\n",
      "Dropped: 1869 (20, 84)\n",
      "Dropped: 1875 (20, 80)\n",
      "Dropped: 1881 (20, 97)\n",
      "Dropped: 1890 (20, 59)\n",
      "Removed percentage: 0.09848088004190676\n",
      "Dropped: 13 (20, 80)\n",
      "Dropped: 14 (20, 74)\n",
      "Dropped: 19 (20, 54)\n",
      "Dropped: 25 (20, 89)\n",
      "Dropped: 26 (20, 87)\n",
      "Dropped: 39 (20, 87)\n",
      "Dropped: 92 (20, 54)\n",
      "Dropped: 111 (20, 73)\n",
      "Dropped: 115 (20, 97)\n",
      "Dropped: 121 (20, 59)\n",
      "Dropped: 165 (20, 63)\n",
      "Dropped: 186 (20, 83)\n",
      "Dropped: 209 (20, 46)\n",
      "Dropped: 211 (20, 89)\n",
      "Dropped: 212 (20, 74)\n",
      "Dropped: 221 (20, 76)\n",
      "Dropped: 224 (20, 73)\n",
      "Dropped: 250 (20, 74)\n",
      "Dropped: 259 (20, 74)\n",
      "Dropped: 284 (20, 54)\n",
      "Dropped: 287 (20, 73)\n",
      "Dropped: 314 (20, 74)\n",
      "Dropped: 323 (20, 93)\n",
      "Dropped: 345 (20, 92)\n",
      "Dropped: 350 (20, 92)\n",
      "Dropped: 352 (20, 84)\n",
      "Dropped: 362 (20, 74)\n",
      "Dropped: 419 (20, 74)\n",
      "Dropped: 429 (20, 97)\n",
      "Dropped: 432 (20, 93)\n",
      "Dropped: 433 (20, 74)\n",
      "Dropped: 440 (20, 72)\n",
      "Dropped: 454 (20, 97)\n",
      "Dropped: 457 (20, 97)\n",
      "Dropped: 459 (20, 92)\n",
      "Dropped: 465 (20, 97)\n",
      "Dropped: 466 (20, 72)\n",
      "Dropped: 471 (20, 93)\n",
      "Dropped: 485 (20, 83)\n",
      "Dropped: 505 (20, 74)\n",
      "Dropped: 537 (20, 97)\n",
      "Dropped: 541 (20, 59)\n",
      "Dropped: 550 (20, 93)\n",
      "Dropped: 564 (20, 76)\n",
      "Dropped: 574 (20, 72)\n",
      "Dropped: 586 (20, 72)\n",
      "Dropped: 594 (20, 83)\n",
      "Dropped: 597 (20, 97)\n",
      "Dropped: 602 (20, 93)\n",
      "Dropped: 648 (20, 73)\n",
      "Dropped: 653 (20, 74)\n",
      "Dropped: 660 (20, 74)\n",
      "Dropped: 664 (20, 89)\n",
      "Dropped: 709 (20, 74)\n",
      "Dropped: 720 (20, 63)\n",
      "Dropped: 737 (20, 50)\n",
      "Dropped: 759 (20, 69)\n",
      "Dropped: 784 (20, 87)\n",
      "Dropped: 789 (20, 63)\n",
      "Dropped: 800 (20, 75)\n",
      "Dropped: 802 (20, 76)\n",
      "Dropped: 805 (20, 89)\n",
      "Dropped: 817 (20, 93)\n",
      "Dropped: 827 (20, 75)\n",
      "Dropped: 831 (20, 80)\n",
      "Dropped: 833 (20, 97)\n",
      "Dropped: 840 (20, 84)\n",
      "Dropped: 842 (20, 80)\n",
      "Dropped: 867 (20, 64)\n",
      "Dropped: 890 (20, 63)\n",
      "Dropped: 901 (20, 97)\n",
      "Dropped: 908 (20, 73)\n",
      "Dropped: 929 (20, 89)\n",
      "Dropped: 932 (20, 84)\n",
      "Dropped: 936 (20, 73)\n",
      "Dropped: 941 (20, 87)\n",
      "Dropped: 947 (20, 41)\n",
      "Dropped: 950 (20, 97)\n",
      "Dropped: 962 (20, 76)\n",
      "Dropped: 972 (20, 97)\n",
      "Dropped: 995 (20, 67)\n",
      "Dropped: 1004 (20, 97)\n",
      "Dropped: 1007 (20, 92)\n",
      "Dropped: 1016 (20, 84)\n",
      "Dropped: 1021 (20, 73)\n",
      "Dropped: 1024 (20, 84)\n",
      "Dropped: 1026 (20, 92)\n",
      "Dropped: 1029 (20, 97)\n",
      "Dropped: 1035 (20, 80)\n",
      "Dropped: 1048 (20, 97)\n",
      "Dropped: 1050 (20, 76)\n",
      "Dropped: 1105 (20, 64)\n",
      "Dropped: 1108 (20, 89)\n",
      "Dropped: 1112 (20, 75)\n",
      "Dropped: 1121 (20, 84)\n",
      "Dropped: 1124 (20, 97)\n",
      "Dropped: 1126 (20, 84)\n",
      "Dropped: 1148 (20, 93)\n",
      "Dropped: 1164 (20, 97)\n",
      "Dropped: 1182 (20, 89)\n",
      "Dropped: 1204 (20, 83)\n",
      "Dropped: 1212 (20, 42)\n",
      "Dropped: 1222 (20, 59)\n",
      "Dropped: 1259 (20, 97)\n",
      "Dropped: 1265 (20, 97)\n",
      "Dropped: 1266 (20, 93)\n",
      "Dropped: 1268 (20, 78)\n",
      "Dropped: 1279 (20, 97)\n",
      "Dropped: 1314 (20, 64)\n",
      "Dropped: 1325 (20, 89)\n",
      "Dropped: 1331 (20, 76)\n",
      "Dropped: 1342 (20, 93)\n",
      "Dropped: 1357 (20, 59)\n",
      "Dropped: 1361 (20, 67)\n",
      "Dropped: 1366 (20, 93)\n",
      "Dropped: 1371 (20, 64)\n",
      "Dropped: 1376 (20, 76)\n",
      "Dropped: 1380 (20, 76)\n",
      "Dropped: 1396 (20, 73)\n",
      "Dropped: 1406 (20, 50)\n",
      "Dropped: 1415 (20, 92)\n",
      "Dropped: 1443 (20, 74)\n",
      "Dropped: 1453 (20, 97)\n",
      "Dropped: 1473 (20, 97)\n",
      "Dropped: 1474 (20, 92)\n",
      "Dropped: 1481 (20, 78)\n",
      "Dropped: 1490 (20, 84)\n",
      "Dropped: 1495 (20, 80)\n",
      "Dropped: 1502 (20, 77)\n",
      "Dropped: 1503 (20, 50)\n",
      "Dropped: 1512 (20, 97)\n",
      "Dropped: 1537 (20, 74)\n",
      "Dropped: 1543 (20, 87)\n",
      "Dropped: 1560 (20, 72)\n",
      "Dropped: 1566 (20, 74)\n",
      "Dropped: 1577 (20, 83)\n",
      "Dropped: 1582 (20, 67)\n",
      "Dropped: 1591 (20, 64)\n",
      "Dropped: 1604 (20, 87)\n",
      "Dropped: 1616 (20, 92)\n",
      "Dropped: 1617 (20, 87)\n",
      "Dropped: 1625 (20, 72)\n",
      "Dropped: 1637 (20, 76)\n",
      "Dropped: 1656 (20, 72)\n",
      "Dropped: 1660 (20, 63)\n",
      "Dropped: 1666 (20, 73)\n",
      "Dropped: 1667 (20, 72)\n",
      "Dropped: 1676 (20, 50)\n",
      "Dropped: 1686 (20, 76)\n",
      "Dropped: 1695 (20, 89)\n",
      "Dropped: 1726 (20, 97)\n",
      "Dropped: 1736 (20, 63)\n",
      "Dropped: 1747 (20, 80)\n",
      "Dropped: 1764 (20, 89)\n",
      "Dropped: 1785 (20, 72)\n",
      "Dropped: 1858 (20, 70)\n",
      "Dropped: 1861 (20, 80)\n",
      "Dropped: 1871 (20, 83)\n",
      "Dropped: 1883 (20, 76)\n",
      "Dropped: 1893 (20, 75)\n",
      "Dropped: 1906 (20, 64)\n",
      "Removed percentage: 0.08433734939759036\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, prob = extract_features(audio_files_train, y_orig_train)\n",
    "print('Removed percentage:', prob / len(y_orig_train))\n",
    "x_val, y_val, prob = extract_features(audio_files_val, y_orig_val)\n",
    "print('Removed percentage:', prob / len(y_orig_val))\n",
    "x_test, y_test, prob = extract_features(audio_files_test, y_orig_test)\n",
    "print('Removed percentage:', prob / len(y_orig_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "engaging-saturn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_npz_name = \"targets.npz\"\n",
    "np.savez(target_npz_name, \n",
    "         x_train=x_train, \n",
    "         y_train=y_train, \n",
    "         x_val=x_val, \n",
    "         y_val=y_val, \n",
    "         x_test=x_test, \n",
    "         y_test=y_test)\n",
    "feature_sets = np.load(target_npz_name)\n",
    "feature_sets.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nearby-national",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13849, 20, 99)\n",
      "(1721, 20, 99)\n",
      "(1748, 20, 99)\n"
     ]
    }
   ],
   "source": [
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "plain-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13849, 20, 99, 1)\n",
      "(20, 99, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], \n",
    "                          1)\n",
    "x_val = x_val.reshape(x_val.shape[0], \n",
    "                      x_val.shape[1], \n",
    "                      x_val.shape[2], \n",
    "                      1)\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                        x_test.shape[1], \n",
    "                        x_test.shape[2], \n",
    "                        1)\n",
    "sample_shape = x_test.shape[1:]\n",
    "print(x_train.shape)\n",
    "print(sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acknowledged-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=sample_shape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(len(targets), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "synthetic-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 19, 98, 32)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 9, 49, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 48, 32)         4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 24, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 24, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 23, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 11, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 704)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               90240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 103,429\n",
      "Trainable params: 103,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "surface-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "conventional-aruba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "139/139 [==============================] - 12s 82ms/step - loss: 2.2348 - accuracy: 0.2117 - val_loss: 1.4758 - val_accuracy: 0.4178\n",
      "Epoch 2/100\n",
      "139/139 [==============================] - 12s 87ms/step - loss: 1.3686 - accuracy: 0.3892 - val_loss: 0.8687 - val_accuracy: 0.7159\n",
      "Epoch 3/100\n",
      "139/139 [==============================] - 14s 101ms/step - loss: 0.9922 - accuracy: 0.5850 - val_loss: 0.6099 - val_accuracy: 0.7931\n",
      "Epoch 4/100\n",
      "139/139 [==============================] - 15s 104ms/step - loss: 0.7852 - accuracy: 0.6945 - val_loss: 0.4672 - val_accuracy: 0.8524\n",
      "Epoch 5/100\n",
      "139/139 [==============================] - 13s 96ms/step - loss: 0.6739 - accuracy: 0.7436 - val_loss: 0.3713 - val_accuracy: 0.8751\n",
      "Epoch 6/100\n",
      "139/139 [==============================] - 14s 101ms/step - loss: 0.5789 - accuracy: 0.7903 - val_loss: 0.3007 - val_accuracy: 0.8937\n",
      "Epoch 7/100\n",
      "139/139 [==============================] - 17s 120ms/step - loss: 0.5003 - accuracy: 0.8159 - val_loss: 0.2874 - val_accuracy: 0.8989\n",
      "Epoch 8/100\n",
      "139/139 [==============================] - 15s 108ms/step - loss: 0.4728 - accuracy: 0.8347 - val_loss: 0.2619 - val_accuracy: 0.9035\n",
      "Epoch 9/100\n",
      "139/139 [==============================] - 15s 107ms/step - loss: 0.4242 - accuracy: 0.8482 - val_loss: 0.2373 - val_accuracy: 0.9192\n",
      "Epoch 10/100\n",
      "139/139 [==============================] - 12s 89ms/step - loss: 0.4178 - accuracy: 0.8513 - val_loss: 0.2216 - val_accuracy: 0.9233\n",
      "Epoch 11/100\n",
      "139/139 [==============================] - 14s 104ms/step - loss: 0.3649 - accuracy: 0.8704 - val_loss: 0.1997 - val_accuracy: 0.9297\n",
      "Epoch 12/100\n",
      "139/139 [==============================] - 16s 113ms/step - loss: 0.3428 - accuracy: 0.8815 - val_loss: 0.1896 - val_accuracy: 0.9367\n",
      "Epoch 13/100\n",
      "139/139 [==============================] - 15s 108ms/step - loss: 0.3337 - accuracy: 0.8859 - val_loss: 0.1809 - val_accuracy: 0.9320\n",
      "Epoch 14/100\n",
      "139/139 [==============================] - 14s 97ms/step - loss: 0.3184 - accuracy: 0.8901 - val_loss: 0.1805 - val_accuracy: 0.9407\n",
      "Epoch 15/100\n",
      "139/139 [==============================] - 15s 107ms/step - loss: 0.3217 - accuracy: 0.8872 - val_loss: 0.1820 - val_accuracy: 0.9372\n",
      "Epoch 16/100\n",
      "139/139 [==============================] - 16s 115ms/step - loss: 0.2769 - accuracy: 0.9016 - val_loss: 0.1623 - val_accuracy: 0.9419\n",
      "Epoch 17/100\n",
      "139/139 [==============================] - 13s 95ms/step - loss: 0.2794 - accuracy: 0.9034 - val_loss: 0.1543 - val_accuracy: 0.9518\n",
      "Epoch 18/100\n",
      "139/139 [==============================] - 14s 104ms/step - loss: 0.2733 - accuracy: 0.9061 - val_loss: 0.1651 - val_accuracy: 0.9390\n",
      "Epoch 19/100\n",
      "139/139 [==============================] - 14s 103ms/step - loss: 0.2659 - accuracy: 0.9114 - val_loss: 0.1456 - val_accuracy: 0.9483\n",
      "Epoch 20/100\n",
      "139/139 [==============================] - 15s 105ms/step - loss: 0.2510 - accuracy: 0.9134 - val_loss: 0.1478 - val_accuracy: 0.9512\n",
      "Epoch 21/100\n",
      "139/139 [==============================] - 15s 108ms/step - loss: 0.2467 - accuracy: 0.9150 - val_loss: 0.1495 - val_accuracy: 0.9483\n",
      "Epoch 22/100\n",
      "139/139 [==============================] - 14s 104ms/step - loss: 0.2291 - accuracy: 0.9189 - val_loss: 0.1454 - val_accuracy: 0.9483\n",
      "Epoch 23/100\n",
      "139/139 [==============================] - 17s 123ms/step - loss: 0.2341 - accuracy: 0.9154 - val_loss: 0.1367 - val_accuracy: 0.9518\n",
      "Epoch 24/100\n",
      "139/139 [==============================] - 15s 107ms/step - loss: 0.2272 - accuracy: 0.9234 - val_loss: 0.1430 - val_accuracy: 0.9506\n",
      "Epoch 25/100\n",
      "139/139 [==============================] - 13s 94ms/step - loss: 0.2273 - accuracy: 0.9197 - val_loss: 0.1311 - val_accuracy: 0.9524\n",
      "Epoch 26/100\n",
      "139/139 [==============================] - 14s 104ms/step - loss: 0.2081 - accuracy: 0.9249 - val_loss: 0.1476 - val_accuracy: 0.9500\n",
      "Epoch 27/100\n",
      "139/139 [==============================] - 14s 100ms/step - loss: 0.2068 - accuracy: 0.9266 - val_loss: 0.1451 - val_accuracy: 0.9506\n",
      "Epoch 28/100\n",
      "139/139 [==============================] - 15s 107ms/step - loss: 0.1910 - accuracy: 0.9315 - val_loss: 0.1264 - val_accuracy: 0.9547\n",
      "Epoch 29/100\n",
      "139/139 [==============================] - 14s 103ms/step - loss: 0.1985 - accuracy: 0.9321 - val_loss: 0.1354 - val_accuracy: 0.9524\n",
      "Epoch 30/100\n",
      "139/139 [==============================] - 12s 90ms/step - loss: 0.2045 - accuracy: 0.9280 - val_loss: 0.1465 - val_accuracy: 0.9494\n",
      "Epoch 31/100\n",
      "139/139 [==============================] - 13s 96ms/step - loss: 0.2039 - accuracy: 0.9272 - val_loss: 0.1275 - val_accuracy: 0.9587\n",
      "Epoch 32/100\n",
      "139/139 [==============================] - 13s 94ms/step - loss: 0.1824 - accuracy: 0.9353 - val_loss: 0.1239 - val_accuracy: 0.9617\n",
      "Epoch 33/100\n",
      "139/139 [==============================] - 13s 95ms/step - loss: 0.1861 - accuracy: 0.9356 - val_loss: 0.1284 - val_accuracy: 0.9576\n",
      "Epoch 34/100\n",
      "139/139 [==============================] - 14s 102ms/step - loss: 0.1822 - accuracy: 0.9401 - val_loss: 0.1173 - val_accuracy: 0.9617\n",
      "Epoch 35/100\n",
      "139/139 [==============================] - 15s 105ms/step - loss: 0.1760 - accuracy: 0.9372 - val_loss: 0.1255 - val_accuracy: 0.9576\n",
      "Epoch 36/100\n",
      "139/139 [==============================] - 15s 108ms/step - loss: 0.1735 - accuracy: 0.9392 - val_loss: 0.1196 - val_accuracy: 0.9605\n",
      "Epoch 37/100\n",
      "139/139 [==============================] - 14s 102ms/step - loss: 0.1735 - accuracy: 0.9379 - val_loss: 0.1218 - val_accuracy: 0.9582\n",
      "Epoch 38/100\n",
      "139/139 [==============================] - 21s 148ms/step - loss: 0.1829 - accuracy: 0.9350 - val_loss: 0.1148 - val_accuracy: 0.9605\n",
      "Epoch 39/100\n",
      "139/139 [==============================] - 15s 112ms/step - loss: 0.1630 - accuracy: 0.9435 - val_loss: 0.1261 - val_accuracy: 0.9558\n",
      "Epoch 40/100\n",
      "139/139 [==============================] - 17s 124ms/step - loss: 0.1573 - accuracy: 0.9440 - val_loss: 0.1117 - val_accuracy: 0.9564\n",
      "Epoch 41/100\n",
      "139/139 [==============================] - 13s 95ms/step - loss: 0.1629 - accuracy: 0.9410 - val_loss: 0.1179 - val_accuracy: 0.9605\n",
      "Epoch 42/100\n",
      "139/139 [==============================] - 12s 83ms/step - loss: 0.1515 - accuracy: 0.9455 - val_loss: 0.1130 - val_accuracy: 0.9593\n",
      "Epoch 43/100\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 0.1569 - accuracy: 0.9460 - val_loss: 0.1100 - val_accuracy: 0.9599\n",
      "Epoch 44/100\n",
      "139/139 [==============================] - 11s 77ms/step - loss: 0.1542 - accuracy: 0.9443 - val_loss: 0.1143 - val_accuracy: 0.9617\n",
      "Epoch 45/100\n",
      "139/139 [==============================] - 11s 81ms/step - loss: 0.1461 - accuracy: 0.9485 - val_loss: 0.1155 - val_accuracy: 0.9640\n",
      "Epoch 46/100\n",
      "139/139 [==============================] - 13s 91ms/step - loss: 0.1479 - accuracy: 0.9494 - val_loss: 0.1062 - val_accuracy: 0.9669\n",
      "Epoch 47/100\n",
      "139/139 [==============================] - 12s 87ms/step - loss: 0.1539 - accuracy: 0.9453 - val_loss: 0.1032 - val_accuracy: 0.9657\n",
      "Epoch 48/100\n",
      "139/139 [==============================] - 11s 81ms/step - loss: 0.1394 - accuracy: 0.9537 - val_loss: 0.1094 - val_accuracy: 0.9611\n",
      "Epoch 49/100\n",
      "139/139 [==============================] - 10s 74ms/step - loss: 0.1433 - accuracy: 0.9504 - val_loss: 0.1160 - val_accuracy: 0.9605\n",
      "Epoch 50/100\n",
      "139/139 [==============================] - 10s 75ms/step - loss: 0.1420 - accuracy: 0.9493 - val_loss: 0.1055 - val_accuracy: 0.9663\n",
      "Epoch 51/100\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.1353 - accuracy: 0.9529 - val_loss: 0.1055 - val_accuracy: 0.9657\n",
      "Epoch 52/100\n",
      "139/139 [==============================] - 9s 65ms/step - loss: 0.1319 - accuracy: 0.9522 - val_loss: 0.1067 - val_accuracy: 0.9617\n",
      "Epoch 53/100\n",
      "139/139 [==============================] - 10s 71ms/step - loss: 0.1350 - accuracy: 0.9523 - val_loss: 0.1029 - val_accuracy: 0.9628\n",
      "Epoch 54/100\n",
      "139/139 [==============================] - 13s 95ms/step - loss: 0.1241 - accuracy: 0.9552 - val_loss: 0.1085 - val_accuracy: 0.9628\n",
      "Epoch 55/100\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 0.1309 - accuracy: 0.9527 - val_loss: 0.1237 - val_accuracy: 0.9599\n",
      "Epoch 56/100\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 0.1524 - accuracy: 0.9457 - val_loss: 0.1139 - val_accuracy: 0.9605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "139/139 [==============================] - 10s 73ms/step - loss: 0.1338 - accuracy: 0.9515 - val_loss: 0.1075 - val_accuracy: 0.9617\n",
      "Epoch 58/100\n",
      "139/139 [==============================] - 13s 93ms/step - loss: 0.1348 - accuracy: 0.9525 - val_loss: 0.1000 - val_accuracy: 0.9646\n",
      "Epoch 59/100\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.1308 - accuracy: 0.9512 - val_loss: 0.1076 - val_accuracy: 0.9640\n",
      "Epoch 60/100\n",
      "139/139 [==============================] - 15s 106ms/step - loss: 0.1449 - accuracy: 0.9505 - val_loss: 0.1110 - val_accuracy: 0.9640\n",
      "Epoch 61/100\n",
      "139/139 [==============================] - 11s 81ms/step - loss: 0.1149 - accuracy: 0.9600 - val_loss: 0.1125 - val_accuracy: 0.9651\n",
      "Epoch 62/100\n",
      "139/139 [==============================] - 11s 79ms/step - loss: 0.1250 - accuracy: 0.9549 - val_loss: 0.1052 - val_accuracy: 0.9617\n",
      "Epoch 63/100\n",
      "139/139 [==============================] - 14s 102ms/step - loss: 0.1186 - accuracy: 0.9562 - val_loss: 0.0995 - val_accuracy: 0.9657\n",
      "Epoch 64/100\n",
      "139/139 [==============================] - 13s 91ms/step - loss: 0.1163 - accuracy: 0.9562 - val_loss: 0.0950 - val_accuracy: 0.9657\n",
      "Epoch 65/100\n",
      "139/139 [==============================] - 11s 77ms/step - loss: 0.1389 - accuracy: 0.9514 - val_loss: 0.1029 - val_accuracy: 0.9617\n",
      "Epoch 66/100\n",
      "139/139 [==============================] - 12s 85ms/step - loss: 0.1196 - accuracy: 0.9583 - val_loss: 0.1048 - val_accuracy: 0.9628\n",
      "Epoch 67/100\n",
      "139/139 [==============================] - 9s 64ms/step - loss: 0.1203 - accuracy: 0.9608 - val_loss: 0.0985 - val_accuracy: 0.9657\n",
      "Epoch 68/100\n",
      "139/139 [==============================] - 10s 72ms/step - loss: 0.1148 - accuracy: 0.9589 - val_loss: 0.1046 - val_accuracy: 0.9663\n",
      "Epoch 69/100\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.1264 - accuracy: 0.9552 - val_loss: 0.0993 - val_accuracy: 0.9675\n",
      "Epoch 70/100\n",
      "139/139 [==============================] - 10s 73ms/step - loss: 0.1220 - accuracy: 0.9554 - val_loss: 0.0986 - val_accuracy: 0.9680\n",
      "Epoch 71/100\n",
      "139/139 [==============================] - 10s 73ms/step - loss: 0.1243 - accuracy: 0.9601 - val_loss: 0.0995 - val_accuracy: 0.9646\n",
      "Epoch 72/100\n",
      "139/139 [==============================] - 11s 80ms/step - loss: 0.1187 - accuracy: 0.9601 - val_loss: 0.0948 - val_accuracy: 0.9675\n",
      "Epoch 73/100\n",
      "139/139 [==============================] - 13s 95ms/step - loss: 0.1198 - accuracy: 0.9599 - val_loss: 0.0946 - val_accuracy: 0.9669\n",
      "Epoch 74/100\n",
      "139/139 [==============================] - 14s 104ms/step - loss: 0.1099 - accuracy: 0.9589 - val_loss: 0.1221 - val_accuracy: 0.9599\n",
      "Epoch 75/100\n",
      "139/139 [==============================] - 15s 111ms/step - loss: 0.1087 - accuracy: 0.9601 - val_loss: 0.1088 - val_accuracy: 0.9628\n",
      "Epoch 76/100\n",
      "139/139 [==============================] - 12s 84ms/step - loss: 0.1251 - accuracy: 0.9581 - val_loss: 0.0984 - val_accuracy: 0.9680\n",
      "Epoch 77/100\n",
      "139/139 [==============================] - 14s 104ms/step - loss: 0.1127 - accuracy: 0.9599 - val_loss: 0.0956 - val_accuracy: 0.9675\n",
      "Epoch 78/100\n",
      "139/139 [==============================] - 16s 113ms/step - loss: 0.1120 - accuracy: 0.9605 - val_loss: 0.1021 - val_accuracy: 0.9680\n",
      "Epoch 79/100\n",
      "139/139 [==============================] - 14s 104ms/step - loss: 0.1119 - accuracy: 0.9574 - val_loss: 0.1148 - val_accuracy: 0.9582\n",
      "Epoch 80/100\n",
      "139/139 [==============================] - 12s 84ms/step - loss: 0.1137 - accuracy: 0.9611 - val_loss: 0.0959 - val_accuracy: 0.9680\n",
      "Epoch 81/100\n",
      "139/139 [==============================] - 15s 107ms/step - loss: 0.1062 - accuracy: 0.9617 - val_loss: 0.0964 - val_accuracy: 0.9704\n",
      "Epoch 82/100\n",
      "139/139 [==============================] - 13s 92ms/step - loss: 0.1100 - accuracy: 0.9609 - val_loss: 0.0860 - val_accuracy: 0.9709\n",
      "Epoch 83/100\n",
      "139/139 [==============================] - 16s 114ms/step - loss: 0.0987 - accuracy: 0.9641 - val_loss: 0.0878 - val_accuracy: 0.9721\n",
      "Epoch 84/100\n",
      "139/139 [==============================] - 16s 117ms/step - loss: 0.1042 - accuracy: 0.9622 - val_loss: 0.0946 - val_accuracy: 0.9680\n",
      "Epoch 85/100\n",
      "139/139 [==============================] - 16s 116ms/step - loss: 0.1002 - accuracy: 0.9648 - val_loss: 0.0986 - val_accuracy: 0.9692\n",
      "Epoch 86/100\n",
      "139/139 [==============================] - 15s 111ms/step - loss: 0.0989 - accuracy: 0.9649 - val_loss: 0.1049 - val_accuracy: 0.9669\n",
      "Epoch 87/100\n",
      "139/139 [==============================] - 15s 109ms/step - loss: 0.1230 - accuracy: 0.9540 - val_loss: 0.1033 - val_accuracy: 0.9675\n",
      "Epoch 88/100\n",
      "139/139 [==============================] - 15s 106ms/step - loss: 0.1019 - accuracy: 0.9615 - val_loss: 0.0926 - val_accuracy: 0.9680\n",
      "Epoch 89/100\n",
      "139/139 [==============================] - 16s 116ms/step - loss: 0.0997 - accuracy: 0.9661 - val_loss: 0.0962 - val_accuracy: 0.9709\n",
      "Epoch 90/100\n",
      "139/139 [==============================] - 15s 107ms/step - loss: 0.1004 - accuracy: 0.9633 - val_loss: 0.1026 - val_accuracy: 0.9692\n",
      "Epoch 91/100\n",
      "139/139 [==============================] - 15s 106ms/step - loss: 0.0973 - accuracy: 0.9632 - val_loss: 0.0937 - val_accuracy: 0.9709\n",
      "Epoch 92/100\n",
      "139/139 [==============================] - 15s 106ms/step - loss: 0.0940 - accuracy: 0.9658 - val_loss: 0.0960 - val_accuracy: 0.9675\n",
      "Epoch 93/100\n",
      "139/139 [==============================] - 17s 124ms/step - loss: 0.0984 - accuracy: 0.9656 - val_loss: 0.0949 - val_accuracy: 0.9698\n",
      "Epoch 94/100\n",
      "139/139 [==============================] - 12s 85ms/step - loss: 0.0902 - accuracy: 0.9700 - val_loss: 0.0838 - val_accuracy: 0.9744\n",
      "Epoch 95/100\n",
      "139/139 [==============================] - 13s 97ms/step - loss: 0.0985 - accuracy: 0.9668 - val_loss: 0.0871 - val_accuracy: 0.9709\n",
      "Epoch 96/100\n",
      "139/139 [==============================] - 15s 110ms/step - loss: 0.0990 - accuracy: 0.9650 - val_loss: 0.0951 - val_accuracy: 0.9692\n",
      "Epoch 97/100\n",
      "139/139 [==============================] - 14s 100ms/step - loss: 0.1009 - accuracy: 0.9647 - val_loss: 0.0903 - val_accuracy: 0.9698\n",
      "Epoch 98/100\n",
      "139/139 [==============================] - 15s 111ms/step - loss: 0.0978 - accuracy: 0.9649 - val_loss: 0.1069 - val_accuracy: 0.9686\n",
      "Epoch 99/100\n",
      "139/139 [==============================] - 14s 102ms/step - loss: 0.1008 - accuracy: 0.9634 - val_loss: 0.0871 - val_accuracy: 0.9721\n",
      "Epoch 100/100\n",
      "139/139 [==============================] - 14s 104ms/step - loss: 0.0934 - accuracy: 0.9672 - val_loss: 0.0919 - val_accuracy: 0.9727\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=100, \n",
    "                    batch_size=100, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e91b61d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "designed-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.save_model(model, \"cmd_recog_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "electric-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 3.0  Prediction: [[3.5213268e-13 4.1076301e-10 2.1772363e-13 1.0000000e+00 3.8205446e-23]]\n",
      "Answer: 1.0  Prediction: [[5.9147165e-10 9.9999988e-01 1.9732356e-10 6.5793600e-08 1.0611068e-08]]\n",
      "Answer: 1.0  Prediction: [[6.0834351e-13 9.9999964e-01 4.1087314e-11 4.1357436e-07 1.6554660e-13]]\n",
      "Answer: 0.0  Prediction: [[9.9856323e-01 8.0705304e-11 3.2419248e-07 7.2405921e-14 1.4364261e-03]]\n",
      "Answer: 2.0  Prediction: [[8.0466198e-06 3.9806075e-16 9.9999189e-01 4.5390351e-14 5.2535533e-15]]\n",
      "Answer: 4.0  Prediction: [[2.5537136e-07 9.0511802e-09 5.1041937e-10 2.7901592e-10 9.9999976e-01]]\n",
      "Answer: 3.0  Prediction: [[0.16947785 0.06432171 0.183809   0.07636041 0.50603104]]\n",
      "Answer: 1.0  Prediction: [[3.4620825e-04 9.7388679e-01 5.2895996e-04 2.4528252e-02 7.0977327e-04]]\n",
      "Answer: 4.0  Prediction: [[1.8490973e-03 4.7588575e-08 4.5090624e-07 1.6503573e-09 9.9815041e-01]]\n",
      "Answer: 0.0  Prediction: [[9.84610081e-01 1.59877636e-05 1.51816355e-02 5.14057952e-08\n",
      "  1.92278225e-04]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 110):\n",
    "    print('Answer:', y_test[i], ' Prediction:', model.predict(np.expand_dims(x_test[i], 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fresh-output",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 6ms/step - loss: 0.1276 - accuracy: 0.9542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12759166955947876, 0.9542334079742432]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "instructional-screening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 95%\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = y_test\n",
    "\n",
    "test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "print(f'Test set accuracy: {test_acc:.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bec0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
